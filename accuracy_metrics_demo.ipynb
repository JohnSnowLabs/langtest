{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "spark = sparknlp.start()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n",
      "ner_dl download started this may take some time.\n",
      "Approximate size to download 13.6 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    "\t\t.setInputCol(\"text\")\\\n",
    "\t\t.setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "\t\t.setInputCols([\"document\"])\\\n",
    "\t\t.setOutputCol(\"token\")\n",
    "\t\n",
    "embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n",
    "\t\t.setInputCols([\"document\", 'token']) \\\n",
    "\t\t.setOutputCol(\"embeddings\")\n",
    "\n",
    "ner = NerDLModel.pretrained(\"ner_dl\", 'en') \\\n",
    "\t\t.setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n",
    "\t\t.setOutputCol(\"ner\")\n",
    "\n",
    "ner_pipeline = Pipeline().setStages([\n",
    "\t\t\t\tdocumentAssembler,\n",
    "\t\t\t\ttokenizer,\n",
    "\t\t\t\tembeddings,\n",
    "\t\t\t\tner\n",
    "    ])\n",
    "ner_model = ner_pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'nlptest' from 'c:\\\\Users\\\\alytarik\\\\Documents\\\\JSL\\\\nlptest\\\\nlptest\\\\__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(nlptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3 = nlptest.Harness(task=\"ner\", model=ner_model, hub=\"johnsnowlabs\", data=\"demo/data/test.conll\", config=\"demo/data/config.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alytarik\\anaconda3\\envs\\nlptest\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nlptest\n",
    "h3 = nlptest.Harness(task=\"ner\", model=\"en_core_web_sm\", hub=\"spacy\", data=\"demo/data/test.conll\", config=\"demo/data/config.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'defaults': {'min_pass_rate': 0.65, 'min_representation': 50},\n",
       " 'tests': {'accuracy': {'min_precision_score': {'O': 0.8}},\n",
       "  'bias': {'replace_to_female_pronouns': {'min_pass_rate': 0.65}},\n",
       "  'robustness': {'lowercase': {'min_pass_rate': 0.65}}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3.configure(\n",
    "    \"demo/data/config.yml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sample(original='-', test_type='min_recall_score', test_case='CARDINAL', expected_results=0.0, actual_results=0.0, transformations=None, category='Accuracy', state='done'), Sample(original='-', test_type='min_recall_score', test_case='DATE', expected_results=0.0, actual_results=0.0, transformations=None, category='Accuracy', state='done'), Sample(original='-', test_type='min_recall_score', test_case='EVENT', expected_results=0.0, actual_results=0.0, transformations=None, category='Accuracy', state='done'), Sample(original='-', test_type='min_recall_score', test_case='GPE', expected_results=0.0, actual_results=0.0, transformations=None, category='Accuracy', state='done'), Sample(original='-', test_type='min_recall_score', test_case='LOC', expected_results=0.0, actual_results=0.0, transformations=None, category='Accuracy', state='done'), Sample(original='-', test_type='min_recall_score', test_case='MISC', expected_results=0.0, actual_results=0.0, transformations=None, category='Accuracy', state='done'), Sample(original='-', test_type='min_recall_score', test_case='NORP', expected_results=0.0, actual_results=0.0, transformations=None, category='Accuracy', state='done'), Sample(original='-', test_type='min_recall_score', test_case='O', expected_results=0.0, actual_results=0.8866571018651362, transformations=None, category='Accuracy', state='done'), Sample(original='-', test_type='min_recall_score', test_case='ORDINAL', expected_results=0.0, actual_results=0.0, transformations=None, category='Accuracy', state='done'), Sample(original='-', test_type='min_recall_score', test_case='ORG', expected_results=0.0, actual_results=0.0, transformations=None, category='Accuracy', state='done'), Sample(original='-', test_type='min_recall_score', test_case='PER', expected_results=0.0, actual_results=0.0, transformations=None, category='Accuracy', state='done'), Sample(original='-', test_type='min_recall_score', test_case='PERSON', expected_results=0.0, actual_results=0.0, transformations=None, category='Accuracy', state='done'), Sample(original='-', test_type='min_recall_score', test_case='TIME', expected_results=0.0, actual_results=0.0, transformations=None, category='Accuracy', state='done')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alytarik\\anaconda3\\envs\\nlptest\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alytarik\\anaconda3\\envs\\nlptest\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alytarik\\anaconda3\\envs\\nlptest\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alytarik\\anaconda3\\envs\\nlptest\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alytarik\\anaconda3\\envs\\nlptest\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alytarik\\anaconda3\\envs\\nlptest\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nlptest.nlptest.Harness at 0x1bffbbb7eb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>test_type</th>\n",
       "      <th>original</th>\n",
       "      <th>test_case</th>\n",
       "      <th>expected_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>min_precision_score</td>\n",
       "      <td>-</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>min_precision_score</td>\n",
       "      <td>-</td>\n",
       "      <td>DATE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>min_precision_score</td>\n",
       "      <td>-</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>min_precision_score</td>\n",
       "      <td>-</td>\n",
       "      <td>GPE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>min_precision_score</td>\n",
       "      <td>-</td>\n",
       "      <td>LOC</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>for , goals against , points ) :</td>\n",
       "      <td>for , goals against , points ) :</td>\n",
       "      <td>[O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>Uzbekistan 1 1 0 0 2 0 3</td>\n",
       "      <td>uzbekistan 1 1 0 0 2 0 3</td>\n",
       "      <td>[B-LOC, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>Japan 1 1 0 0 2 1 3</td>\n",
       "      <td>japan 1 1 0 0 2 1 3</td>\n",
       "      <td>[B-LOC, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>Syria 1 0 0 1 1 2 0</td>\n",
       "      <td>syria 1 0 0 1 1 2 0</td>\n",
       "      <td>[B-LOC, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>China 1 0 0 1 0 2 0</td>\n",
       "      <td>china 1 0 0 1 0 2 0</td>\n",
       "      <td>[B-LOC, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category            test_type                          original  \\\n",
       "0      Accuracy  min_precision_score                                 -   \n",
       "1      Accuracy  min_precision_score                                 -   \n",
       "2      Accuracy  min_precision_score                                 -   \n",
       "3      Accuracy  min_precision_score                                 -   \n",
       "4      Accuracy  min_precision_score                                 -   \n",
       "..          ...                  ...                               ...   \n",
       "190  Robustness            lowercase  for , goals against , points ) :   \n",
       "191  Robustness            lowercase          Uzbekistan 1 1 0 0 2 0 3   \n",
       "192  Robustness            lowercase               Japan 1 1 0 0 2 1 3   \n",
       "193  Robustness            lowercase               Syria 1 0 0 1 1 2 0   \n",
       "194  Robustness            lowercase               China 1 0 0 1 0 2 0   \n",
       "\n",
       "                            test_case               expected_result  \n",
       "0                            CARDINAL                           0.0  \n",
       "1                                DATE                           0.0  \n",
       "2                               EVENT                           0.0  \n",
       "3                                 GPE                           0.0  \n",
       "4                                 LOC                           0.0  \n",
       "..                                ...                           ...  \n",
       "190  for , goals against , points ) :      [O, O, O, O, O, O, O, O]  \n",
       "191          uzbekistan 1 1 0 0 2 0 3  [B-LOC, O, O, O, O, O, O, O]  \n",
       "192               japan 1 1 0 0 2 1 3  [B-LOC, O, O, O, O, O, O, O]  \n",
       "193               syria 1 0 0 1 1 2 0  [B-LOC, O, O, O, O, O, O, O]  \n",
       "194               china 1 0 0 1 0 2 0  [B-LOC, O, O, O, O, O, O, O]  \n",
       "\n",
       "[195 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3.testcases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>test_type</th>\n",
       "      <th>fail_count</th>\n",
       "      <th>pass_count</th>\n",
       "      <th>pass_rate</th>\n",
       "      <th>minimum_pass_rate</th>\n",
       "      <th>pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>min_precision_score</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>100%</td>\n",
       "      <td>65%</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bias</td>\n",
       "      <td>replace_to_female_pronouns</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>99%</td>\n",
       "      <td>65%</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robustness</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>48</td>\n",
       "      <td>43</td>\n",
       "      <td>47%</td>\n",
       "      <td>65%</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                   test_type  fail_count  pass_count pass_rate  \\\n",
       "0    Accuracy         min_precision_score           0          13      100%   \n",
       "1        Bias  replace_to_female_pronouns           1          90       99%   \n",
       "2  Robustness                   lowercase          48          43       47%   \n",
       "\n",
       "  minimum_pass_rate   pass  \n",
       "0               65%   True  \n",
       "1               65%   True  \n",
       "2               65%  False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3.run().report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>test_type</th>\n",
       "      <th>original</th>\n",
       "      <th>test_case</th>\n",
       "      <th>expected_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>min_precision_score</td>\n",
       "      <td>-</td>\n",
       "      <td>LOC</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>min_precision_score</td>\n",
       "      <td>-</td>\n",
       "      <td>MISC</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>min_precision_score</td>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>min_precision_score</td>\n",
       "      <td>-</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>min_precision_score</td>\n",
       "      <td>-</td>\n",
       "      <td>PER</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bias</td>\n",
       "      <td>replace_to_female_pronouns</td>\n",
       "      <td>SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRI...</td>\n",
       "      <td>SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRI...</td>\n",
       "      <td>[O, O, B-LOC, O, O, O, O, B-LOC, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bias</td>\n",
       "      <td>replace_to_female_pronouns</td>\n",
       "      <td>Nadim Ladki</td>\n",
       "      <td>Nadim Ladki</td>\n",
       "      <td>[B-ORG, I-ORG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bias</td>\n",
       "      <td>replace_to_female_pronouns</td>\n",
       "      <td>AL-AIN , United Arab Emirates 1996-12-06</td>\n",
       "      <td>AL-AIN , United Arab Emirates 1996-12-06</td>\n",
       "      <td>[B-LOC, O, B-LOC, I-LOC, I-LOC, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bias</td>\n",
       "      <td>replace_to_female_pronouns</td>\n",
       "      <td>Japan began the defence of their Asian Cup tit...</td>\n",
       "      <td>Japan began the defence of her Asian Cup title...</td>\n",
       "      <td>[B-LOC, O, O, O, O, O, B-MISC, I-MISC, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bias</td>\n",
       "      <td>replace_to_female_pronouns</td>\n",
       "      <td>But China saw their luck desert them in the se...</td>\n",
       "      <td>But China saw hers luck desert her in the seco...</td>\n",
       "      <td>[O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                   test_type  \\\n",
       "0  Accuracy         min_precision_score   \n",
       "1  Accuracy         min_precision_score   \n",
       "2  Accuracy         min_precision_score   \n",
       "3  Accuracy         min_precision_score   \n",
       "4  Accuracy         min_precision_score   \n",
       "5      Bias  replace_to_female_pronouns   \n",
       "6      Bias  replace_to_female_pronouns   \n",
       "7      Bias  replace_to_female_pronouns   \n",
       "8      Bias  replace_to_female_pronouns   \n",
       "9      Bias  replace_to_female_pronouns   \n",
       "\n",
       "                                            original  \\\n",
       "0                                                  -   \n",
       "1                                                  -   \n",
       "2                                                  -   \n",
       "3                                                  -   \n",
       "4                                                  -   \n",
       "5  SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRI...   \n",
       "6                                        Nadim Ladki   \n",
       "7           AL-AIN , United Arab Emirates 1996-12-06   \n",
       "8  Japan began the defence of their Asian Cup tit...   \n",
       "9  But China saw their luck desert them in the se...   \n",
       "\n",
       "                                           test_case  \\\n",
       "0                                                LOC   \n",
       "1                                               MISC   \n",
       "2                                                  O   \n",
       "3                                                ORG   \n",
       "4                                                PER   \n",
       "5  SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRI...   \n",
       "6                                        Nadim Ladki   \n",
       "7           AL-AIN , United Arab Emirates 1996-12-06   \n",
       "8  Japan began the defence of her Asian Cup title...   \n",
       "9  But China saw hers luck desert her in the seco...   \n",
       "\n",
       "                                     expected_result  \n",
       "0                                                0.0  \n",
       "1                                                0.0  \n",
       "2                                                0.0  \n",
       "3                                                0.0  \n",
       "4                                                0.0  \n",
       "5       [O, O, B-LOC, O, O, O, O, B-LOC, O, O, O, O]  \n",
       "6                                     [B-ORG, I-ORG]  \n",
       "7                 [B-LOC, O, B-LOC, I-LOC, I-LOC, O]  \n",
       "8  [B-LOC, O, O, O, O, O, B-MISC, I-MISC, O, O, O...  \n",
       "9  [O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3.testcases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3.generated_results_df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 4.3.0\n",
      "Apache Spark version: 3.2.3\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "spark = sparknlp.start() \n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"description\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "use = UniversalSentenceEncoder.pretrained()\\\n",
    " .setInputCols([\"document\"])\\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "classsifierdl = ClassifierDLApproach()\\\n",
    "  .setInputCols([\"sentence_embeddings\"])\\\n",
    "  .setOutputCol(\"class\")\\\n",
    "  .setLabelColumn(\"category\")\\\n",
    "  .setMaxEpochs(5)\\\n",
    "  .setEnableOutputLogs(True)\n",
    "use_clf_pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        use,\n",
    "        classsifierdl\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = spark.read \\\n",
    "      .option(\"header\", True) \\\n",
    "      .csv(\"demo/data/news_category_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pipelineModel = use_clf_pipeline.fit(trainDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlptest import Harness\n",
    "\n",
    "h = Harness(\"text-classification\", use_pipelineModel, \"sparknlp\", data=\"demo/data/news_category_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'defaults': {'min_pass_rate': 0.65, 'min_representation': 50},\n",
       " 'tests': {'bias': {'replace_to_female_pronouns': {'min_pass_rate': 0.65},\n",
       "   'replace_to_male_pronouns': {'min_pass_rate': 0.65}},\n",
       "  'robustness': {'lowercase': {'min_pass_rate': 0.65},\n",
       "   'swap_entities': {'min_pass_rate': 0.65},\n",
       "   'uppercase': {'min_pass_rate': 0.65},\n",
       "   'add_context': {'min_pass_rate': 0.65,\n",
       "    'parameters': {'ending_context': ['Bye', 'Reported'],\n",
       "     'starting_context': ['Hi', 'Good morning', 'Hello']}}}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.configure(\"demo/data/config.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace_to_female_pronouns\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h\u001b[39m.\u001b[39;49mgenerate()\u001b[39m.\u001b[39mrun()\u001b[39m.\u001b[39mreport()\n",
      "File \u001b[1;32mc:\\Users\\alytarik\\Documents\\JSL\\nlptest\\nlptest\\nlptest.py:94\u001b[0m, in \u001b[0;36mHarness.generate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[39mGenerates the testcases to be used when evaluating the model.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \n\u001b[0;32m     90\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39m    None: The generated testcases are stored in `_testcases` attribute.\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     93\u001b[0m tests \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config[\u001b[39m'\u001b[39m\u001b[39mtests\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_testcases \u001b[39m=\u001b[39m TestFactory\u001b[39m.\u001b[39;49mtransform(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, tests)\n\u001b[0;32m     95\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alytarik\\Documents\\JSL\\nlptest\\nlptest\\transform\\__init__.py:63\u001b[0m, in \u001b[0;36mTestFactory.transform\u001b[1;34m(data, test_types)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39mfor\u001b[39;00m each \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(test_types\u001b[39m.\u001b[39mkeys()):\n\u001b[0;32m     61\u001b[0m     values \u001b[39m=\u001b[39m test_types[each]\n\u001b[0;32m     62\u001b[0m     all_results\u001b[39m.\u001b[39mextend(\n\u001b[1;32m---> 63\u001b[0m         all_categories[each](data, values)\u001b[39m.\u001b[39;49mtransform()\n\u001b[0;32m     64\u001b[0m     )\n\u001b[0;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m all_results\n",
      "File \u001b[1;32mc:\\Users\\alytarik\\Documents\\JSL\\nlptest\\nlptest\\transform\\__init__.py:346\u001b[0m, in \u001b[0;36mBias.transform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[39mfor\u001b[39;00m test_name, params \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtests\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    345\u001b[0m     \u001b[39mprint\u001b[39m(test_name)\n\u001b[1;32m--> 346\u001b[0m     data_handler_copy \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_handler]\n\u001b[0;32m    347\u001b[0m     transformed_samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupported_tests[test_name]\u001b[39m.\u001b[39mtransform(data_handler_copy, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mparameters\u001b[39m\u001b[39m'\u001b[39m, {}))\n\u001b[0;32m    348\u001b[0m     \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m transformed_samples:\n",
      "File \u001b[1;32mc:\\Users\\alytarik\\Documents\\JSL\\nlptest\\nlptest\\transform\\__init__.py:346\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[39mfor\u001b[39;00m test_name, params \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtests\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    345\u001b[0m     \u001b[39mprint\u001b[39m(test_name)\n\u001b[1;32m--> 346\u001b[0m     data_handler_copy \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39;49mcopy() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_handler]\n\u001b[0;32m    347\u001b[0m     transformed_samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupported_tests[test_name]\u001b[39m.\u001b[39mtransform(data_handler_copy, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mparameters\u001b[39m\u001b[39m'\u001b[39m, {}))\n\u001b[0;32m    348\u001b[0m     \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m transformed_samples:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "h.generate().run().report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlptest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c9408a94318707e8fdb8545d68f8a52ae12a13199d278674e95b123dca71b57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
