---
layout: docs
header: true
seotitle: CommonsenseQA Benchmark | LangTest | John Snow Labs
title: CommonsenseQA
key: benchmarks-commonsenseqa
permalink: /docs/pages/benchmarks/commonsenseqa/
aside:
    toc: true
sidebar:
    nav: benchmarks
show_edit_on_github: true
nav_key: benchmarks
modify_date: "2019-05-16"
---

### CommonsenseQA
The CommonsenseQA dataset is a multiple-choice question answering dataset that aims to test the ability of natural language processing models to answer questions that require commonsense knowledge. The dataset consists of questions with five choices each. The questions were generated by Amazon Mechanical Turk workers, who were asked to create questions based on a given source concept and three target concepts related to it. The questions require different types of commonsense knowledge to predict the correct answers. The dataset covers various topics such as science, history, and everyday life.

You can see which subsets and splits are available and the other details of the dataset [here](docs/pages/docs/data#question-answering).

{:.table2}
| question                                                                                     | answer |
| -------------------------------------------------------------------------------------------- | ------ |
| If you jump in any of the oceans you will get? A. tanned B. wet C. wide D. very deep E. fish | B. wet |
