---
layout: docs
header: true
seotitle: Medical Benchmark Datasets | LangTest | John Snow Labs
title: Medical Benchmark Datasets
key: notebooks
permalink: /docs/pages/benchmarks/medical/
aside:
    toc: true
sidebar:
    nav: benchmarks
show_edit_on_github: true
nav_key: benchmarks
modify_date: "2019-05-16"
---


<div class="main-docs" markdown="1">
<div class="h3-box" markdown="1">

LangTest provides support for a variety of benchmark datasets in the medical field which are listed below in the table, allowing you to assess the performance of your models on medical queries.

</div>
</div>


{:.table2}
| Dataset                                   | Task               | Category | Source                                                                                                                                                 | Colab                                                                                                                                                                                                                                      |
| ----------------------------------------- | ------------------ | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| [**MedMCQA**](medmcqa)              | question-answering | `robustness`, `accuracy`, `fairness`        | [MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering](https://proceedings.mlr.press/v174/pal22a)  | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/langtest/blob/main/demo/tutorials/llm_notebooks/dataset-notebooks/Medical_Datasets.ipynb)             |
| [**MedQA**](medqa)              | question-answering | `robustness`, `accuracy`, `fairness`        | [What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams](https://paperswithcode.com/dataset/medqa-usmle) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/langtest/blob/main/demo/tutorials/llm_notebooks/dataset-notebooks/Medical_Datasets.ipynb)             |
| [**PubMedQA**](pubmedqa)              | question-answering | `robustness`, `accuracy`, `fairness`        | [PubMedQA: A Dataset for Biomedical Research Question Answering](https://arxiv.org/abs/1909.06146)| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/langtest/blob/main/demo/tutorials/llm_notebooks/dataset-notebooks/Medical_Datasets.ipynb)             |