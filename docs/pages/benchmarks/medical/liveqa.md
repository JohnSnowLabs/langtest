---
layout: docs
header: true
seotitle: LiveQA Benchmark | LangTest | John Snow Labs
title: LiveQA
key: benchmarks-LiveQA
permalink: /docs/pages/benchmarks/medical/LiveQA/
aside:
    toc: true
sidebar:
    nav: benchmarks
show_edit_on_github: true
nav_key: benchmarks
modify_date: "2019-05-16"
---


**Source:** [Overview of the Medical Question Answering Task at TREC 2017 LiveQA](https://trec.nist.gov/pubs/trec26/papers/Overview-QA.pdf)

The LiveQA'17 medical task focuses on consumer health question answering. Consumer health questions were received by the U.S. National Library of Medicine (NLM). The dataset consists of constructed medical question-answer pairs for training and testing, with additional annotations that can be used to develop question analysis and question answering systems.

{:.table2}
| subsets       | Details                                                                                                                                                                                                           |
|-------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **LiveQA-Test**    | This dataset does not contain labels, so accuracy and fairness tests cannot be run on it. Only robustness tests can be applied.                             |
