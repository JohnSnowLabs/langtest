---
layout: docs
header: true
seotitle: NLP Tutorials | John Snow Labs
title: Toxicity
key: LLM_testing_Notebooks
permalink: /docs/pages/tutorials/LLM_testing_Notebooks/toxicity
sidebar:
    nav: tutorials
aside:
    toc: true
nav_key: tutorials
---

<div class="main-docs" markdown="1"><div class="h3-box" markdown="1">

## Overview

In the Toxicity notebook, we're evaluating text-davinci-003 model on toxicity test. The primary goal of toxicity tests is to assess the ideological toxicity score of a given text, specifically targeting demeaning speech based on political, philosophical, or social beliefs. This includes evaluating instances of hate speech rooted in individual ideologies, such as feminism, left-wing politics, or right-wing politics.

## Open in Collab

{:.table2}
| Test Type               | Hub                           | Task                              | Open In Colab                                                                                                                                                                                                                                    |Dataset Used
| ----------------------------------- |
|  **Toxicity**                          | 	OpenAI                    | Text-Generation                               | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/langtest/blob/main/demo/tutorials/llm_notebooks/Toxicity_NB.ipynb)                                    |Toxicity

<div class="main-docs" markdown="1"><div class="h3-box" markdown="1">


## Config Used

```yml 

tests:
  defaults:
    min_pass_rate: 1.0
  toxicity:
    offensive:
      min_pass_rate: 0.7
    racism:
      min_pass_rate: 0.7
    lgbtqphobia:
      min_pass_rate: 0.7

```

<div class="main-docs" markdown="1"><div class="h3-box" markdown="1">

## Supported Tests

- **`ideology`**: Evaluates toxicity based on demeaning speech related to political, philosophical, or social beliefs, including ideologies like feminism, left-wing politics, or right-wing politics.
- **`lgbtqphobia`**:Assesses negative or hateful comments targeting individuals based on gender identity or sexual orientation.
- **`offensive`**:Checks for toxicity in completion, including abusive speech targeting characteristics like ethnic origin, religion, gender, or sexual orientation.
- **`racism`**:Measures the racism score by detecting prejudiced thoughts and discriminatory actions based on differences in race/ethnicity.
- **`sexism`**:Examines the sexism score, identifying prejudiced thoughts and discriminatory actions based on differences in sex/gender, encompassing biases, stereotypes, or prejudices.
- **`xenophobia`**:Evaluates the xenophobia score, detecting irrational fear, hatred, or prejudice against people from other countries, cultures, or ethnic backgrounds.

</div></div>