Search.setIndex({"docnames": ["autosummary/langtest", "autosummary/langtest.augmentation", "autosummary/langtest.augmentation.AugmentRobustness", "autosummary/langtest.augmentation.BaseAugmentaion", "autosummary/langtest.datahandler", "autosummary/langtest.datahandler.datasource", "autosummary/langtest.datahandler.datasource.CSVDataset", "autosummary/langtest.datahandler.datasource.ConllDataset", "autosummary/langtest.datahandler.datasource.DataFactory", "autosummary/langtest.datahandler.datasource.JSONDataset", "autosummary/langtest.datahandler.datasource.JSONLDataset", "autosummary/langtest.datahandler.format", "autosummary/langtest.datahandler.format.BaseFormatter", "autosummary/langtest.datahandler.format.Formatter", "autosummary/langtest.datahandler.format.NEROutputFormatter", "autosummary/langtest.datahandler.format.SequenceClassificationOutputFormatter", "autosummary/langtest.modelhandler", "autosummary/langtest.modelhandler.jsl_modelhandler", "autosummary/langtest.modelhandler.jsl_modelhandler.PretrainedModelForNER", "autosummary/langtest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification", "autosummary/langtest.modelhandler.llm_modelhandler", "autosummary/langtest.modelhandler.llm_modelhandler.PretrainedModelForQA", "autosummary/langtest.modelhandler.modelhandler", "autosummary/langtest.modelhandler.modelhandler.ModelFactory", "autosummary/langtest.modelhandler.spacy_modelhandler", "autosummary/langtest.modelhandler.spacy_modelhandler.PretrainedModelForNER", "autosummary/langtest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification", "autosummary/langtest.modelhandler.transformers_modelhandler", "autosummary/langtest.modelhandler.transformers_modelhandler.PretrainedModelForNER", "autosummary/langtest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification", "autosummary/langtest.langtest", "autosummary/langtest.langtest.Harness", "autosummary/langtest.testrunner", "autosummary/langtest.testrunner.BaseRunner", "autosummary/langtest.testrunner.TestRunner", "autosummary/langtest.transform", "autosummary/langtest.transform.AccuracyTestFactory", "autosummary/langtest.transform.BiasTestFactory", "autosummary/langtest.transform.FairnessTestFactory", "autosummary/langtest.transform.ITests", "autosummary/langtest.transform.RepresentationTestFactory", "autosummary/langtest.transform.RobustnessTestFactory", "autosummary/langtest.transform.TestFactory", "autosummary/langtest.transform.accuracy", "autosummary/langtest.transform.accuracy.BaseAccuracy", "autosummary/langtest.transform.accuracy.MinF1Score", "autosummary/langtest.transform.accuracy.MinMacroF1Score", "autosummary/langtest.transform.accuracy.MinMicroF1Score", "autosummary/langtest.transform.accuracy.MinPrecisionScore", "autosummary/langtest.transform.accuracy.MinRecallScore", "autosummary/langtest.transform.accuracy.MinWeightedF1Score", "autosummary/langtest.transform.bias", "autosummary/langtest.transform.bias.BaseBias", "autosummary/langtest.transform.bias.CountryEconomicBias", "autosummary/langtest.transform.bias.EthnicityNameBias", "autosummary/langtest.transform.bias.GenderPronounBias", "autosummary/langtest.transform.bias.ReligionBias", "autosummary/langtest.transform.fairness", "autosummary/langtest.transform.fairness.BaseFairness", "autosummary/langtest.transform.fairness.MaxGenderF1Score", "autosummary/langtest.transform.fairness.MinGenderF1Score", "autosummary/langtest.transform.fairness.get_gendered_data", "autosummary/langtest.transform.representation", "autosummary/langtest.transform.representation.BaseRepresentation", "autosummary/langtest.transform.representation.CountryEconomicRepresentation", "autosummary/langtest.transform.representation.EthnicityRepresentation", "autosummary/langtest.transform.representation.GenderRepresentation", "autosummary/langtest.transform.representation.LabelRepresentation", "autosummary/langtest.transform.representation.ReligionRepresentation", "autosummary/langtest.transform.robustness", "autosummary/langtest.transform.robustness.AddContext", "autosummary/langtest.transform.robustness.AddContraction", "autosummary/langtest.transform.robustness.AddPunctuation", "autosummary/langtest.transform.robustness.AddTypo", "autosummary/langtest.transform.robustness.BaseRobustness", "autosummary/langtest.transform.robustness.ConvertAccent", "autosummary/langtest.transform.robustness.LowerCase", "autosummary/langtest.transform.robustness.StripPunctuation", "autosummary/langtest.transform.robustness.SwapEntities", "autosummary/langtest.transform.robustness.TitleCase", "autosummary/langtest.transform.robustness.UpperCase", "autosummary/langtest.transform.utils", "autosummary/langtest.transform.utils.check_name", "autosummary/langtest.transform.utils.create_terminology", "autosummary/langtest.transform.utils.get_country_economic_representation_dict", "autosummary/langtest.transform.utils.get_entity_representation_proportions", "autosummary/langtest.transform.utils.get_ethnicity_representation_dict", "autosummary/langtest.transform.utils.get_label_representation_dict", "autosummary/langtest.transform.utils.get_religion_name_representation_dict", "autosummary/langtest.transform.utils.get_substitution_names", "autosummary/langtest.utils", "autosummary/langtest.utils.custom_types", "autosummary/langtest.utils.custom_types.helpers", "autosummary/langtest.utils.custom_types.helpers.Span", "autosummary/langtest.utils.custom_types.helpers.Transformation", "autosummary/langtest.utils.custom_types.output", "autosummary/langtest.utils.custom_types.output.MaxScoreOutput", "autosummary/langtest.utils.custom_types.output.MinScoreOutput", "autosummary/langtest.utils.custom_types.output.NEROutput", "autosummary/langtest.utils.custom_types.output.SequenceClassificationOutput", "autosummary/langtest.utils.custom_types.predictions", "autosummary/langtest.utils.custom_types.predictions.NERPrediction", "autosummary/langtest.utils.custom_types.predictions.SequenceLabel", "autosummary/langtest.utils.custom_types.sample", "autosummary/langtest.utils.custom_types.sample.BaseQASample", "autosummary/langtest.utils.custom_types.sample.BaseSample", "autosummary/langtest.utils.custom_types.sample.MaxScoreSample", "autosummary/langtest.utils.custom_types.sample.MinScoreSample", "autosummary/langtest.utils.custom_types.sample.NERSample", "autosummary/langtest.utils.custom_types.sample.QASample", "autosummary/langtest.utils.custom_types.sample.SequenceClassificationSample", "autosummary/langtest.utils.gender_classifier", "autosummary/langtest.utils.gender_classifier.GenderClassifier", "autosummary/langtest.utils.lib_manager", "autosummary/langtest.utils.lib_manager.try_import_lib", "api", "index", "quick_start"], "filenames": ["autosummary/langtest.rst", "autosummary/langtest.augmentation.rst", "autosummary/langtest.augmentation.AugmentRobustness.rst", "autosummary/langtest.augmentation.BaseAugmentaion.rst", "autosummary/langtest.datahandler.rst", "autosummary/langtest.datahandler.datasource.rst", "autosummary/langtest.datahandler.datasource.CSVDataset.rst", "autosummary/langtest.datahandler.datasource.ConllDataset.rst", "autosummary/langtest.datahandler.datasource.DataFactory.rst", "autosummary/langtest.datahandler.datasource.JSONDataset.rst", "autosummary/langtest.datahandler.datasource.JSONLDataset.rst", "autosummary/langtest.datahandler.format.rst", "autosummary/langtest.datahandler.format.BaseFormatter.rst", "autosummary/langtest.datahandler.format.Formatter.rst", "autosummary/langtest.datahandler.format.NEROutputFormatter.rst", "autosummary/langtest.datahandler.format.SequenceClassificationOutputFormatter.rst", "autosummary/langtest.modelhandler.rst", "autosummary/langtest.modelhandler.jsl_modelhandler.rst", "autosummary/langtest.modelhandler.jsl_modelhandler.PretrainedModelForNER.rst", "autosummary/langtest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification.rst", "autosummary/langtest.modelhandler.llm_modelhandler.rst", "autosummary/langtest.modelhandler.llm_modelhandler.PretrainedModelForQA.rst", "autosummary/langtest.modelhandler.modelhandler.rst", "autosummary/langtest.modelhandler.modelhandler.ModelFactory.rst", "autosummary/langtest.modelhandler.spacy_modelhandler.rst", "autosummary/langtest.modelhandler.spacy_modelhandler.PretrainedModelForNER.rst", "autosummary/langtest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification.rst", "autosummary/langtest.modelhandler.transformers_modelhandler.rst", "autosummary/langtest.modelhandler.transformers_modelhandler.PretrainedModelForNER.rst", "autosummary/langtest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification.rst", "autosummary/langtest.langtest.rst", "autosummary/langtest.langtest.Harness.rst", "autosummary/langtest.testrunner.rst", "autosummary/langtest.testrunner.BaseRunner.rst", "autosummary/langtest.testrunner.TestRunner.rst", "autosummary/langtest.transform.rst", "autosummary/langtest.transform.AccuracyTestFactory.rst", "autosummary/langtest.transform.BiasTestFactory.rst", "autosummary/langtest.transform.FairnessTestFactory.rst", "autosummary/langtest.transform.ITests.rst", "autosummary/langtest.transform.RepresentationTestFactory.rst", "autosummary/langtest.transform.RobustnessTestFactory.rst", "autosummary/langtest.transform.TestFactory.rst", "autosummary/langtest.transform.accuracy.rst", "autosummary/langtest.transform.accuracy.BaseAccuracy.rst", "autosummary/langtest.transform.accuracy.MinF1Score.rst", "autosummary/langtest.transform.accuracy.MinMacroF1Score.rst", "autosummary/langtest.transform.accuracy.MinMicroF1Score.rst", "autosummary/langtest.transform.accuracy.MinPrecisionScore.rst", "autosummary/langtest.transform.accuracy.MinRecallScore.rst", "autosummary/langtest.transform.accuracy.MinWeightedF1Score.rst", "autosummary/langtest.transform.bias.rst", "autosummary/langtest.transform.bias.BaseBias.rst", "autosummary/langtest.transform.bias.CountryEconomicBias.rst", "autosummary/langtest.transform.bias.EthnicityNameBias.rst", "autosummary/langtest.transform.bias.GenderPronounBias.rst", "autosummary/langtest.transform.bias.ReligionBias.rst", "autosummary/langtest.transform.fairness.rst", "autosummary/langtest.transform.fairness.BaseFairness.rst", "autosummary/langtest.transform.fairness.MaxGenderF1Score.rst", "autosummary/langtest.transform.fairness.MinGenderF1Score.rst", "autosummary/langtest.transform.fairness.get_gendered_data.rst", "autosummary/langtest.transform.representation.rst", "autosummary/langtest.transform.representation.BaseRepresentation.rst", "autosummary/langtest.transform.representation.CountryEconomicRepresentation.rst", "autosummary/langtest.transform.representation.EthnicityRepresentation.rst", "autosummary/langtest.transform.representation.GenderRepresentation.rst", "autosummary/langtest.transform.representation.LabelRepresentation.rst", "autosummary/langtest.transform.representation.ReligionRepresentation.rst", "autosummary/langtest.transform.robustness.rst", "autosummary/langtest.transform.robustness.AddContext.rst", "autosummary/langtest.transform.robustness.AddContraction.rst", "autosummary/langtest.transform.robustness.AddPunctuation.rst", "autosummary/langtest.transform.robustness.AddTypo.rst", "autosummary/langtest.transform.robustness.BaseRobustness.rst", "autosummary/langtest.transform.robustness.ConvertAccent.rst", "autosummary/langtest.transform.robustness.LowerCase.rst", "autosummary/langtest.transform.robustness.StripPunctuation.rst", "autosummary/langtest.transform.robustness.SwapEntities.rst", "autosummary/langtest.transform.robustness.TitleCase.rst", "autosummary/langtest.transform.robustness.UpperCase.rst", "autosummary/langtest.transform.utils.rst", "autosummary/langtest.transform.utils.check_name.rst", "autosummary/langtest.transform.utils.create_terminology.rst", "autosummary/langtest.transform.utils.get_country_economic_representation_dict.rst", "autosummary/langtest.transform.utils.get_entity_representation_proportions.rst", "autosummary/langtest.transform.utils.get_ethnicity_representation_dict.rst", "autosummary/langtest.transform.utils.get_label_representation_dict.rst", "autosummary/langtest.transform.utils.get_religion_name_representation_dict.rst", "autosummary/langtest.transform.utils.get_substitution_names.rst", "autosummary/langtest.utils.rst", "autosummary/langtest.utils.custom_types.rst", "autosummary/langtest.utils.custom_types.helpers.rst", "autosummary/langtest.utils.custom_types.helpers.Span.rst", "autosummary/langtest.utils.custom_types.helpers.Transformation.rst", "autosummary/langtest.utils.custom_types.output.rst", "autosummary/langtest.utils.custom_types.output.MaxScoreOutput.rst", "autosummary/langtest.utils.custom_types.output.MinScoreOutput.rst", "autosummary/langtest.utils.custom_types.output.NEROutput.rst", "autosummary/langtest.utils.custom_types.output.SequenceClassificationOutput.rst", "autosummary/langtest.utils.custom_types.predictions.rst", "autosummary/langtest.utils.custom_types.predictions.NERPrediction.rst", "autosummary/langtest.utils.custom_types.predictions.SequenceLabel.rst", "autosummary/langtest.utils.custom_types.sample.rst", "autosummary/langtest.utils.custom_types.sample.BaseQASample.rst", "autosummary/langtest.utils.custom_types.sample.BaseSample.rst", "autosummary/langtest.utils.custom_types.sample.MaxScoreSample.rst", "autosummary/langtest.utils.custom_types.sample.MinScoreSample.rst", "autosummary/langtest.utils.custom_types.sample.NERSample.rst", "autosummary/langtest.utils.custom_types.sample.QASample.rst", "autosummary/langtest.utils.custom_types.sample.SequenceClassificationSample.rst", "autosummary/langtest.utils.gender_classifier.rst", "autosummary/langtest.utils.gender_classifier.GenderClassifier.rst", "autosummary/langtest.utils.lib_manager.rst", "autosummary/langtest.utils.lib_manager.try_import_lib.rst", "api.rst", "index.rst", "quick_start.rst"], "titles": ["langtest", "langtest.augmentation", "langtest.augmentation.AugmentRobustness", "langtest.augmentation.BaseAugmentaion", "langtest.datahandler", "langtest.datahandler.datasource", "langtest.datahandler.datasource.CSVDataset", "langtest.datahandler.datasource.ConllDataset", "langtest.datahandler.datasource.DataFactory", "langtest.datahandler.datasource.JSONDataset", "langtest.datahandler.datasource.JSONLDataset", "langtest.datahandler.format", "langtest.datahandler.format.BaseFormatter", "langtest.datahandler.format.Formatter", "langtest.datahandler.format.NEROutputFormatter", "langtest.datahandler.format.SequenceClassificationOutputFormatter", "langtest.modelhandler", "langtest.modelhandler.jsl_modelhandler", "langtest.modelhandler.jsl_modelhandler.PretrainedModelForNER", "langtest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification", "langtest.modelhandler.llm_modelhandler", "langtest.modelhandler.llm_modelhandler.PretrainedModelForQA", "langtest.modelhandler.modelhandler", "langtest.modelhandler.modelhandler.ModelFactory", "langtest.modelhandler.spacy_modelhandler", "langtest.modelhandler.spacy_modelhandler.PretrainedModelForNER", "langtest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification", "langtest.modelhandler.transformers_modelhandler", "langtest.modelhandler.transformers_modelhandler.PretrainedModelForNER", "langtest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification", "langtest.langtest", "langtest.langtest.Harness", "langtest.testrunner", "langtest.testrunner.BaseRunner", "langtest.testrunner.TestRunner", "langtest.transform", "langtest.transform.AccuracyTestFactory", "langtest.transform.BiasTestFactory", "langtest.transform.FairnessTestFactory", "langtest.transform.ITests", "langtest.transform.RepresentationTestFactory", "langtest.transform.RobustnessTestFactory", "langtest.transform.TestFactory", "langtest.transform.accuracy", "langtest.transform.accuracy.BaseAccuracy", "langtest.transform.accuracy.MinF1Score", "langtest.transform.accuracy.MinMacroF1Score", "langtest.transform.accuracy.MinMicroF1Score", "langtest.transform.accuracy.MinPrecisionScore", "langtest.transform.accuracy.MinRecallScore", "langtest.transform.accuracy.MinWeightedF1Score", "langtest.transform.bias", "langtest.transform.bias.BaseBias", "langtest.transform.bias.CountryEconomicBias", "langtest.transform.bias.EthnicityNameBias", "langtest.transform.bias.GenderPronounBias", "langtest.transform.bias.ReligionBias", "langtest.transform.fairness", "langtest.transform.fairness.BaseFairness", "langtest.transform.fairness.MaxGenderF1Score", "langtest.transform.fairness.MinGenderF1Score", "langtest.transform.fairness.get_gendered_data", "langtest.transform.representation", "langtest.transform.representation.BaseRepresentation", "langtest.transform.representation.CountryEconomicRepresentation", "langtest.transform.representation.EthnicityRepresentation", "langtest.transform.representation.GenderRepresentation", "langtest.transform.representation.LabelRepresentation", "langtest.transform.representation.ReligionRepresentation", "langtest.transform.robustness", "langtest.transform.robustness.AddContext", "langtest.transform.robustness.AddContraction", "langtest.transform.robustness.AddPunctuation", "langtest.transform.robustness.AddTypo", "langtest.transform.robustness.BaseRobustness", "langtest.transform.robustness.ConvertAccent", "langtest.transform.robustness.LowerCase", "langtest.transform.robustness.StripPunctuation", "langtest.transform.robustness.SwapEntities", "langtest.transform.robustness.TitleCase", "langtest.transform.robustness.UpperCase", "langtest.transform.utils", "langtest.transform.utils.check_name", "langtest.transform.utils.create_terminology", "langtest.transform.utils.get_country_economic_representation_dict", "langtest.transform.utils.get_entity_representation_proportions", "langtest.transform.utils.get_ethnicity_representation_dict", "langtest.transform.utils.get_label_representation_dict", "langtest.transform.utils.get_religion_name_representation_dict", "langtest.transform.utils.get_substitution_names", "langtest.utils", "langtest.utils.custom_types", "langtest.utils.custom_types.helpers", "langtest.utils.custom_types.helpers.Span", "langtest.utils.custom_types.helpers.Transformation", "langtest.utils.custom_types.output", "langtest.utils.custom_types.output.MaxScoreOutput", "langtest.utils.custom_types.output.MinScoreOutput", "langtest.utils.custom_types.output.NEROutput", "langtest.utils.custom_types.output.SequenceClassificationOutput", "langtest.utils.custom_types.predictions", "langtest.utils.custom_types.predictions.NERPrediction", "langtest.utils.custom_types.predictions.SequenceLabel", "langtest.utils.custom_types.sample", "langtest.utils.custom_types.sample.BaseQASample", "langtest.utils.custom_types.sample.BaseSample", "langtest.utils.custom_types.sample.MaxScoreSample", "langtest.utils.custom_types.sample.MinScoreSample", "langtest.utils.custom_types.sample.NERSample", "langtest.utils.custom_types.sample.QASample", "langtest.utils.custom_types.sample.SequenceClassificationSample", "langtest.utils.gender_classifier", "langtest.utils.gender_classifier.GenderClassifier", "langtest.utils.lib_manager", "langtest.utils.lib_manager.try_import_lib", "&lt;no title&gt;", "LangTest Documentation", "Quick Start"], "terms": {"1": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "modul": [0, 4, 16, 35, 90, 91], "class": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112], "task": [2, 6, 7, 8, 10, 23, 31, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 98, 99, 104, 105, 109, 116], "h_report": 2, "config": [2, 31, 45, 46, 47, 48, 49, 50, 64, 65, 66, 67, 68, 70, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "max_prop": 2, "5": 2, "base": [2, 3, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 21, 23, 25, 26, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 112, 117], "baseaugmentaion": 2, "A": [2, 14, 18, 23, 25, 28, 31, 36, 37, 38, 39, 40, 41, 42, 44, 52, 58, 63, 74], "perform": [2, 3, 13, 18, 19, 21, 23, 25, 26, 28, 29, 31, 36, 37, 38, 40, 41, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "specifi": [2, 13, 23, 37, 38, 39, 40, 41, 42, 64, 65, 66, 67, 68, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "histor": 2, "result": [2, 13, 31, 34, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 64, 65, 66, 67, 68, 104, 105, 106, 107, 108, 109, 110], "string": [2, 12, 13, 14, 15, 19, 25, 29, 55, 72, 76, 77, 79, 80, 82, 83, 98, 99], "indic": 2, "being": 2, "type": [2, 3, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 23, 25, 26, 28, 29, 31, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 84, 85, 86, 87, 88, 89, 98, 99, 104, 105, 106, 107, 108, 110, 112, 116], "str": [2, 6, 7, 8, 9, 10, 13, 14, 15, 18, 19, 21, 23, 25, 26, 28, 29, 31, 36, 37, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 72, 74, 75, 77, 78, 82, 83, 84, 86, 87, 88, 89, 93, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 112, 114], "dictionari": [2, 31, 36, 37, 38, 39, 40, 41, 42, 70, 71, 75, 78, 83, 84, 85, 86, 87, 88, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "contain": [2, 14, 15, 31, 33, 34, 84, 85, 86, 87, 88, 116], "configur": [2, 31, 44, 45, 46, 47, 48, 49, 50], "paramet": [2, 12, 13, 14, 15, 18, 19, 23, 25, 26, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 112], "dict": [2, 18, 28, 31, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 75, 78, 83, 84, 85, 86, 87, 88, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "datafram": [2, 31, 33, 83], "report": [2, 31, 117], "panda": [2, 83], "The": [2, 8, 12, 13, 14, 15, 18, 28, 31, 36, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 84, 86, 87, 88, 104, 105, 108, 117], "maximum": [2, 59], "proport": [2, 64, 65, 66, 67, 68, 85], "improv": 2, "can": [2, 117], "suggest": 2, "method": [2, 3, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 21, 23, 25, 26, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 112], "default": [2, 31, 41, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "float": [2, 96, 97, 101, 102], "__init__": [2, 3, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 21, 23, 25, 26, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 112], "self": [2, 63], "none": [2, 3, 6, 7, 8, 10, 14, 31, 33, 34, 36, 37, 38, 40, 41, 70, 72, 75, 77, 78, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "initi": [2, 6, 7, 8, 9, 10, 23, 31, 33, 34, 41], "an": [2, 31, 39, 44, 52, 53, 54, 55, 56, 58, 59, 60, 63, 74, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "instanc": [2, 8, 18, 19, 31, 41, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "myclass": 2, "fix": [2, 3], "list": [2, 6, 7, 8, 9, 10, 18, 19, 23, 25, 26, 28, 29, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 86, 87, 88, 89, 98, 99, 105, 106, 107, 108, 110], "sampl": [2, 6, 7, 8, 9, 10, 13, 14, 15, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 84, 86, 87, 88], "prop": 2, "calcul": 2, "test": [2, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 59, 63, 64, 65, 66, 67, 68, 84, 86, 87, 88, 96, 97], "given": [2, 23, 31, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 59, 60, 94], "return": [2, 3, 6, 7, 8, 10, 12, 13, 14, 15, 18, 19, 23, 25, 26, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 87, 88, 89, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 112], "input_path": [2, 31], "output_path": [2, 6, 7, 8, 9, 10, 31], "inplac": [2, 31], "bool": [2, 18, 19, 25, 26, 28, 29, 31, 82, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 114], "fals": [2, 19, 26, 29, 31, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "appli": [2, 53, 54, 55, 56, 72, 73, 76, 77, 79, 80, 108], "perturb": [2, 34, 53, 54, 55, 56, 75, 104, 105, 108], "input": [2, 13, 14, 15, 18, 19, 21, 23, 25, 26, 28, 29, 31, 41, 44, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 84, 86, 87, 88, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "data": [2, 3, 6, 7, 8, 9, 10, 31, 33, 34, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 84, 86, 87, 88, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "recommend": 2, "from": [2, 6, 7, 10, 18, 19, 23, 26, 28, 29, 31, 39, 42, 54, 77, 78, 83, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 117], "har": [2, 117], "path": [2, 6, 7, 8, 9, 10, 18, 19, 23, 25, 26, 28, 29, 31], "file": [2, 6, 7, 8, 9, 10, 31], "save": [2, 6, 7, 8, 9, 10, 31], "option": [2, 13, 19, 25, 26, 28, 29, 31, 41, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 116], "If": [2, 13, 23, 31, 64, 65, 66, 67, 68, 108], "true": [2, 44, 45, 46, 47, 48, 49, 50, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "i": [2, 3, 8, 13, 18, 19, 23, 31, 41, 64, 65, 66, 67, 68, 72, 76, 77, 79, 80, 82, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "modifi": [2, 31], "place": 2, "otherwis": 2, "new": [2, 31, 41, 78, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 117], "ar": [2, 31, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "add": [2, 72, 73, 77, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "ani": [2, 31, 44, 45, 46, 47, 48, 49, 50, 52, 58, 60, 63, 74, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "categori": [2, 42, 104, 105, 106, 107, 108, 109, 110], "includ": [2, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "pass": [2, 13, 31, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "rate": 2, "minimum": [2, 45, 46, 47, 48, 49, 50, 60], "follow": [2, 117], "column": [2, 31, 83], "each": [2, 42, 85, 104, 105], "test_typ": [2, 42, 104, 105, 106, 107, 108, 109, 110], "ratio": 2, "divid": 2, "proportion_increas": 2, "how": [2, 94, 117], "much": 2, "should": [2, 3, 12, 15, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 117], "increas": 2, "reach": 2, "abc": [3, 12, 15, 39, 44, 52, 58, 63, 74], "abstract": [3, 12, 15, 33, 39, 44, 52, 53, 54, 55, 56, 58, 63, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "techniqu": 3, "implement": [3, 12, 15, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "child": 3, "thi": [3, 12, 13, 15, 31, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 116], "oper": [3, 104, 105], "rais": [3, 12, 13, 15, 23, 31, 64, 65, 66, 67, 68, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "notimplementederror": [3, 12, 15], "file_path": [6, 7, 8, 9, 10], "_idataset": [6, 7, 9, 10], "handl": [6, 7, 9, 10], "csv": [6, 12, 13, 14, 15], "dataset": [6, 7, 8, 9, 10, 31, 36, 37, 38, 40, 41, 54, 67], "subclass": [6, 7, 9, 10, 12, 13, 15, 34, 45, 46, 47, 48, 49, 50, 59, 60, 64, 65, 66, 67, 68], "object": [6, 7, 8, 9, 10, 13, 14, 15, 23, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 66, 94, 104, 105, 112, 117], "param": [6, 7, 8, 9, 10, 18, 23, 28, 44, 45, 46, 47, 48, 49, 50, 58, 59, 60, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 79, 80], "evalu": [6, 8, 23, 31, 33, 34, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 84, 86, 87, 88], "attribut": [6, 18, 19, 23, 26, 28, 29, 31, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 112], "export_data": [6, 7, 9, 10], "export": [6, 7, 8, 9, 10], "correspond": [6, 7, 8, 9, 10, 36, 37, 38, 40, 41, 42, 78, 83, 104, 105], "format": [6, 7, 8, 9, 10, 31, 83], "load_data": [6, 7, 10], "load": [6, 7, 8, 10, 18, 19, 23, 25, 26, 28, 29, 31], "sentenc": [6, 7, 53, 54, 55, 56, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 108], "rtype": [6, 7, 10], "conll": [7, 12, 13, 14, 15, 31], "nersampl": 7, "factori": [8, 23, 42, 66], "creat": [8, 42, 44, 45, 46, 47, 48, 49, 50, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 117], "respons": 8, "correct": [8, 105, 106, 107, 108, 110], "extens": 8, "text": [8, 10, 18, 19, 21, 23, 25, 26, 28, 29, 34, 83, 93, 94, 99, 102, 104, 105, 108, 112], "json": [9, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "boolq": 10, "boolqdataset": 10, "jsonl": 10, "qasampl": 10, "defin": [12, 13, 39], "formatt": [12, 14, 15], "static": [12, 13, 14, 15, 18, 19, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "to_csv": [12, 13, 14, 15], "to_conl": [12, 13, 14, 15], "custom_typ": [12, 15], "convert": [12, 13, 14, 15, 70, 71, 75, 83, 98, 99], "custom": [12, 13, 14, 15, 23], "represent": [12, 14, 15, 40, 84, 85, 86, 87, 88, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "between": 13, "differ": [13, 31, 39, 42], "output": [13, 19, 23, 44, 52, 58, 59, 60, 63, 74], "us": [13, 14, 15, 23, 29, 31, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 108, 117], "baseformatt": [13, 14, 15], "convers": [13, 70, 71, 75], "appropri": 13, "select": 13, "expect": 13, "argument": [13, 14, 15, 25, 28, 29, 31, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "process": [13, 70, 71, 75, 78], "output_format": 13, "arg": [13, 18, 19, 21, 23, 25, 26, 29, 42, 52], "kwarg": [13, 18, 19, 21, 23, 25, 26, 28, 29, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "either": [13, 23, 33, 34], "posit": 13, "keyword": [13, 25, 28, 29, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "nameerror": 13, "neroutput": [14, 18, 23, 25, 28, 108], "repres": [14, 15, 33, 34, 36, 37, 38, 39, 40, 41], "temp_id": 14, "int": [14, 84, 86, 87, 88, 93, 101], "tupl": [14, 33, 108], "temporari": 14, "id": 14, "group": [14, 18, 25, 28, 29], "entiti": [14, 18, 25, 28, 29, 78, 83, 85, 101], "document": 14, "delimit": [14, 15], "charact": [14, 15], "along": [14, 31], "sequenceclassificationoutput": [15, 19, 23, 26, 29], "model": [18, 19, 21, 23, 25, 26, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 112, 117], "nlupipelin": [18, 19], "pretrainedpipelin": [18, 19], "lightpipelin": [18, 19], "pipelinemodel": [18, 19], "_modelhandl": [18, 19, 21, 25, 26, 28, 29], "sparknlp": [18, 19, 33, 34], "infer": [18, 19], "group_ent": [18, 25, 28], "find": [18, 28], "togeth": [18, 28], "adjac": [18, 28], "token": [18, 28, 70], "same": [18, 28, 104, 105], "predict": [18, 19, 21, 23, 25, 26, 28, 29, 34, 44, 45, 46, 47, 48, 49, 50, 83, 98, 99, 104, 105, 108, 112], "inspir": [18, 28], "adapt": [18, 28], "huggingfac": [18, 28], "transform": [18, 28, 29, 33, 34, 105, 106, 107, 108, 110, 116, 117], "pipelin": [18, 25, 26, 28, 29], "is_ner_annot": 18, "model_inst": [18, 19], "check": [18, 19, 53, 54, 55, 56, 82], "ner": [18, 19, 25, 28, 29, 98, 108, 117], "support": [18, 19, 23, 104, 105, 116], "classmethod": [18, 19, 23, 25, 26, 28, 29, 31, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "load_model": [18, 19, 23, 25, 26, 28, 29], "pretrain": [18, 19, 25, 26, 28], "local": [18, 19, 23], "nlp": [18, 19, 31], "hub": [18, 19, 21, 23, 31, 117], "name": [18, 25, 28, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 74, 78, 89, 101], "recogn": [18, 25, 28], "predict_raw": [18, 19, 23, 25, 26, 28, 29], "label": [18, 19, 25, 26, 28, 29, 67, 78, 83, 87, 102, 112], "is_classifi": 19, "classifi": [19, 26, 112], "return_all_scor": [19, 26, 29], "score": [19, 26, 45, 46, 47, 48, 49, 50, 59, 60, 101, 102], "all": [19, 26, 31, 34, 36, 37, 38, 40, 41, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 117], "classif": [19, 26, 29, 99, 102], "instanti": 23, "valueerror": [23, 31, 64, 65, 66, 67, 68], "disk": 23, "union": 23, "spaci": [25, 26, 33, 34], "addit": [25, 28, 29, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "form": [25, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "properti": [26, 29, 104, 105, 106, 107, 108, 110], "truncation_strategi": 29, "longest_first": 29, "strategi": [29, 70], "truncat": 29, "too": 29, "long": 29, "sequenc": 29, "gener": [31, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 117], "which": [31, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "modelfactori": [31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "requir": 31, "invalid": 31, "augment": [31, 116], "locat": 31, "whether": [31, 104, 105], "directli": 31, "call": [31, 104, 105], "pass_rat": 31, "minimum_pass_r": 31, "have": [31, 72], "unexpect": 31, "augmentrobust": 31, "exampl": 31, "train": 31, "augmented_train": 31, "testcas": [31, 33, 34], "when": 31, "store": [31, 104, 105], "_testcas": 31, "generated_result": 31, "overal": 31, "everi": 31, "textcas": 31, "labelwis": 31, "metric": 31, "pd": [31, 33], "save_dir": 31, "previous": 31, "folder": 31, "need": [31, 53, 54, 55, 56, 104, 105, 106, 107, 108, 110], "previou": 31, "run": [31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 112, 117], "datafactori": 31, "reus": 31, "later": 31, "after": [31, 36, 37, 38, 40, 41], "load_testcas": [33, 34], "model_handl": [33, 34, 42], "spark": [33, 34], "handler": [33, 34], "baserunn": 34, "robust": [34, 36, 37, 38, 40, 41], "both": [34, 70], "origin": [34, 104, 105, 106, 107, 108, 110], "one": [34, 78, 94, 104, 105, 108], "data_handl": [36, 37, 38, 40, 41], "itest": [36, 37, 38, 40, 41], "accuraci": [36, 58, 96, 97], "available_test": [36, 37, 38, 39, 40, 41], "get": [36, 37, 38, 40, 41, 89, 117], "avail": [36, 37, 38, 39, 40, 41, 42], "kei": [36, 37, 38, 40, 41], "valu": [36, 37, 38, 40, 41, 44, 45, 46, 47, 48, 49, 50, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "sample_list": [36, 37, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "raw_data": 36, "raw": 36, "bia": 37, "map": [37, 38, 39, 40, 41, 42], "scenario": [37, 38, 39, 40, 41, 42], "fair": 38, "async": [42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "async_run": [42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "samples_list": 42, "test_categori": 42, "test_scenario": 42, "measur": [44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "alias_nam": [44, 45, 46, 47, 48, 49, 50, 52, 58, 59, 60, 63, 64, 65, 66, 67, 68, 74], "identifi": [44, 52, 58, 59, 60, 63, 64, 65, 66, 67, 68, 74], "minscoresampl": [44, 45, 46, 47, 48, 49, 50, 60], "y_true": [44, 45, 46, 47, 48, 49, 50], "y_pred": [44, 45, 46, 47, 48, 49, 50], "baseaccuraci": [45, 46, 47, 48, 49, 50], "precis": [45, 46, 47, 48, 49], "min_precision_scor": [45, 46, 48, 49], "comput": [45, 46, 47, 48, 49, 50, 58, 59, 60, 63, 64, 65, 66, 67, 68], "f1": [45, 46, 47, 48, 50, 59, 60], "recal": 49, "weight": 50, "creation": [52, 53, 54, 55, 56], "asyncio": [52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "basebia": [53, 54, 55, 56], "country_names_to_substitut": 53, "chosen_country_nam": 53, "replac": [53, 54, 55, 56], "countri": [53, 64, 84], "ethnic": [53, 54, 65, 86], "substitut": [53, 54, 55, 56, 89], "names_to_substitut": [54, 56], "chosen_ethnicity_nam": 54, "curat": 54, "unit": 54, "state": [54, 104, 105, 106, 107, 108, 109, 110], "censu": 54, "bureau": 54, "survei": 54, "pronouns_to_substitut": 55, "pronoun_typ": 55, "pronoun": 55, "gender": [55, 59, 61, 66, 112], "male": 55, "femal": 55, "neutral": 55, "chosen_nam": 56, "religion": [56, 68, 88], "function": [57, 81, 89, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 113], "basefair": [59, 60], "maxscoresampl": 59, "max": 59, "min_f1": 60, "split": 61, "baserepresent": [64, 65, 66, 67, 68], "econom": [64, 84], "actual": [64, 65, 66, 67, 68], "sum": [64, 65, 66, 67, 68], "greater": [64, 65, 66, 67, 68], "than": [64, 65, 66, 67, 68], "enthic": 65, "baserobust": [70, 71, 72, 73, 75, 76, 77, 78, 79, 80], "starting_context": 70, "ending_context": 70, "adjust": 70, "where": 70, "context": 70, "ad": [70, 108], "start": [70, 93, 116], "end": [70, 72, 77, 93], "combin": 70, "term": [70, 75], "beg": 70, "randomli": 70, "whitelist": [72, 77], "punctuat": [72, 77], "skip": [72, 77], "typo": 73, "keyboard": 73, "swap": [73, 78], "introduc": 73, "accent_map": 75, "accent": 75, "isn": 77, "t": [77, 105, 106, 107, 108, 110], "strip": 77, "terminologi": [78, 83], "extract": 78, "make": [78, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "chang": [78, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "accord": [78, 108], "word": [78, 82, 83, 93], "name_list": 82, "look": 82, "potenti": 82, "candid": 82, "ner_data": 83, "iter": 83, "over": [83, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 116], "iob": 83, "io": 83, "ha": 83, "2": 83, "inform": [84, 85, 86, 87, 88, 94], "entity_represent": 85, "values_list": 89, "helper": [89, 104, 105, 112], "basemodel": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105], "": 93, "slice": 93, "pars": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "valid": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "validationerror": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "cannot": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "construct": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "_fields_set": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "setstr": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "set": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "__dict__": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "__fields_set__": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "trust": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "pre": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "respect": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "other": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "behav": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "extra": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "allow": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "wa": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "sinc": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "copi": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "abstractsetintstr": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "mappingintstrani": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "exclud": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "updat": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "dictstrani": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "deep": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "duplic": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "choos": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "field": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "take": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "preced": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "note": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "befor": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "you": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 117], "by_alia": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "skip_default": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "exclude_unset": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "exclude_default": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "exclude_non": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "encod": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "callabl": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "models_as_dict": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "dumps_kwarg": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "unicod": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "per": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "suppli": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "dump": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "update_forward_ref": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "localn": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "try": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "forwardref": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "globaln": [93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110], "original_span": 94, "span": [94, 101, 108], "new_span": 94, "ignor": [94, 105, 106, 107, 108, 110], "keep": 94, "track": 94, "alter": 94, "piec": [94, 112], "It": 94, "hold": 94, "about": 94, "anoth": 94, "max_scor": 96, "min_scor": 97, "nerpredict": [98, 108], "to_str_list": [98, 99], "sequencelabel": 99, "entity_group": 101, "doc_id": 101, "doc_nam": 101, "pos_tag": 101, "chunk_tag": 101, "singl": [101, 102], "obtain": [101, 102], "recognit": 101, "original_quest": [104, 109], "original_context": [104, 109], "perturbed_quest": [104, 109], "perturbed_context": [104, 109], "expected_result": [104, 105, 106, 107, 108, 109, 110], "actual_result": [104, 105, 106, 107, 108, 109, 110], "dataset_nam": [104, 109], "them": [104, 105], "specif": [104, 105], "here": [104, 105], "agnost": [104, 105], "onli": [104, 105], "access": [104, 105], "is_pass": [104, 105], "assess": [104, 105], "regardless": [104, 105], "downstream": [104, 105], "py": [104, 105], "wai": [104, 105], "xxxoutput": [104, 105], "overload": [104, 105], "__eq__": [104, 105], "variabl": [104, 105], "test_cas": [105, 106, 107, 108, 110], "irrelevant_transform": [105, 106, 107, 108, 110], "retriev": [105, 106, 107, 108, 110], "do": [105, 106, 107, 108, 110], "taken": [105, 106, 107, 108, 110], "account": [105, 106, 107, 108, 110], "realign": [105, 106, 107, 108, 110], "relevant_transform": [105, 106, 107, 108, 110], "shouldn": [105, 106, 107, 108, 110], "sort_transform": [105, 106, 107, 108, 110], "v": [105, 106, 107, 108, 110], "ensur": [105, 106, 107, 108, 110], "order": [105, 106, 107, 108, 110], "to_dict": [105, 106, 107, 108, 109, 110], "version": [105, 106, 107, 108, 109, 110], "basesampl": [106, 107, 108, 110], "get_aligned_span_pair": 108, "align": 108, "achiev": 108, "couldn": 108, "ignored_predict": 108, "becaus": 108, "realigned_span": 108, "charg": 108, "shift": 108, "were": 108, "we": [108, 117], "dure": 108, "baseqasampl": 109, "through": 112, "lib": 114, "page": 116, "technic": 116, "librari": 116, "For": 116, "depth": 116, "explan": 116, "around": 116, "usag": 116, "pleas": 116, "head": 116, "langtest": [116, 117], "org": 116, "quick": 116, "altern": 116, "instal": 116, "api": 116, "refer": [116, 117], "datahandl": 116, "modelhandl": 116, "testrunn": 116, "util": 116, "up": 117, "pypi": 117, "pip": 117, "import": 117, "h": 117, "dslim": 117, "bert": 117, "your": 117, "case": 117, "python": 117, "virtualenv": 117, "python3": 117, "8": 117, "sourc": 117, "bin": 117, "activ": 117, "jupyt": 117, "now": 117, "readi": 117, "notebook": 117, "also": 117, "conda": 117, "environ": 117, "manag": 117, "depend": 117, "Then": 117, "packag": 117, "n": 117, "3": 117, "y": 117, "c": 117}, "objects": {"": [[0, 0, 0, "-", "langtest"]], "langtest": [[1, 0, 0, "-", "augmentation"], [4, 0, 0, "-", "datahandler"], [16, 0, 0, "-", "modelhandler"], [30, 0, 0, "-", "langtest"], [32, 0, 0, "-", "testrunner"], [35, 0, 0, "-", "transform"], [90, 0, 0, "-", "utils"]], "langtest.augmentation": [[2, 1, 1, "", "AugmentRobustness"], [3, 1, 1, "", "BaseAugmentaion"]], "langtest.augmentation.AugmentRobustness": [[2, 2, 1, "id0", "__init__"], [2, 3, 1, "", "config"], [2, 2, 1, "id1", "fix"], [2, 3, 1, "", "h_report"], [2, 3, 1, "", "max_prop"], [2, 2, 1, "id2", "suggestions"], [2, 3, 1, "", "task"]], "langtest.augmentation.BaseAugmentaion": [[3, 3, 1, "", "None"], [3, 2, 1, "", "__init__"], [3, 2, 1, "id0", "fix"]], "langtest.datahandler": [[5, 0, 0, "-", "datasource"], [11, 0, 0, "-", "format"]], "langtest.datahandler.datasource": [[6, 1, 1, "", "CSVDataset"], [7, 1, 1, "", "ConllDataset"], [8, 1, 1, "", "DataFactory"], [9, 1, 1, "", "JSONDataset"], [10, 1, 1, "", "JSONLDataset"]], "langtest.datahandler.datasource.CSVDataset": [[6, 2, 1, "", "__init__"], [6, 2, 1, "", "export_data"], [6, 2, 1, "", "load_data"]], "langtest.datahandler.datasource.ConllDataset": [[7, 2, 1, "", "__init__"], [7, 2, 1, "", "export_data"], [7, 2, 1, "", "load_data"]], "langtest.datahandler.datasource.DataFactory": [[8, 2, 1, "", "__init__"], [8, 2, 1, "", "export"], [8, 2, 1, "", "load"]], "langtest.datahandler.datasource.JSONDataset": [[9, 2, 1, "", "__init__"], [9, 2, 1, "", "export_data"]], "langtest.datahandler.datasource.JSONLDataset": [[10, 2, 1, "", "__init__"], [10, 2, 1, "", "export_data"], [10, 2, 1, "", "load_data"]], "langtest.datahandler.format": [[12, 1, 1, "", "BaseFormatter"], [13, 1, 1, "", "Formatter"], [14, 1, 1, "", "NEROutputFormatter"], [15, 1, 1, "", "SequenceClassificationOutputFormatter"]], "langtest.datahandler.format.BaseFormatter": [[12, 2, 1, "", "__init__"], [12, 2, 1, "", "to_conll"], [12, 2, 1, "", "to_csv"]], "langtest.datahandler.format.Formatter": [[13, 2, 1, "", "__init__"], [13, 2, 1, "", "process"]], "langtest.datahandler.format.NEROutputFormatter": [[14, 2, 1, "", "__init__"], [14, 2, 1, "", "to_conll"], [14, 2, 1, "", "to_csv"]], "langtest.datahandler.format.SequenceClassificationOutputFormatter": [[15, 2, 1, "", "__init__"], [15, 2, 1, "", "to_conll"], [15, 2, 1, "", "to_csv"]], "langtest.modelhandler": [[17, 0, 0, "-", "jsl_modelhandler"], [20, 0, 0, "-", "llm_modelhandler"], [22, 0, 0, "-", "modelhandler"], [24, 0, 0, "-", "spacy_modelhandler"], [27, 0, 0, "-", "transformers_modelhandler"]], "langtest.modelhandler.jsl_modelhandler": [[18, 1, 1, "", "PretrainedModelForNER"], [19, 1, 1, "", "PretrainedModelForTextClassification"]], "langtest.modelhandler.jsl_modelhandler.PretrainedModelForNER": [[18, 2, 1, "", "__init__"], [18, 2, 1, "", "group_entities"], [18, 2, 1, "", "is_ner_annotator"], [18, 2, 1, "", "load_model"], [18, 3, 1, "id0", "model"], [18, 2, 1, "", "predict"], [18, 2, 1, "", "predict_raw"]], "langtest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification": [[19, 2, 1, "", "__init__"], [19, 2, 1, "", "is_classifier"], [19, 2, 1, "", "load_model"], [19, 3, 1, "id0", "model"], [19, 2, 1, "", "predict"], [19, 2, 1, "", "predict_raw"]], "langtest.modelhandler.llm_modelhandler": [[21, 1, 1, "", "PretrainedModelForQA"]], "langtest.modelhandler.llm_modelhandler.PretrainedModelForQA": [[21, 2, 1, "", "__init__"], [21, 2, 1, "", "predict"]], "langtest.modelhandler.modelhandler": [[23, 1, 1, "", "ModelFactory"]], "langtest.modelhandler.modelhandler.ModelFactory": [[23, 2, 1, "", "__init__"], [23, 2, 1, "", "load_model"], [23, 2, 1, "", "predict"], [23, 2, 1, "", "predict_raw"]], "langtest.modelhandler.spacy_modelhandler": [[25, 1, 1, "", "PretrainedModelForNER"], [26, 1, 1, "", "PretrainedModelForTextClassification"]], "langtest.modelhandler.spacy_modelhandler.PretrainedModelForNER": [[25, 2, 1, "", "__init__"], [25, 2, 1, "", "load_model"], [25, 2, 1, "", "predict"], [25, 2, 1, "", "predict_raw"]], "langtest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification": [[26, 2, 1, "", "__init__"], [26, 4, 1, "", "labels"], [26, 2, 1, "", "load_model"], [26, 2, 1, "", "predict"], [26, 2, 1, "", "predict_raw"]], "langtest.modelhandler.transformers_modelhandler": [[28, 1, 1, "", "PretrainedModelForNER"], [29, 1, 1, "", "PretrainedModelForTextClassification"], [27, 3, 1, "", "model"]], "langtest.modelhandler.transformers_modelhandler.PretrainedModelForNER": [[28, 2, 1, "", "__init__"], [28, 2, 1, "", "group_entities"], [28, 2, 1, "", "load_model"], [28, 3, 1, "id0", "model"], [28, 2, 1, "", "predict"], [28, 2, 1, "", "predict_raw"]], "langtest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification": [[29, 2, 1, "", "__init__"], [29, 4, 1, "", "labels"], [29, 2, 1, "", "load_model"], [29, 3, 1, "", "model"], [29, 2, 1, "", "predict"], [29, 2, 1, "", "predict_raw"]], "langtest.langtest": [[31, 1, 1, "", "Harness"]], "langtest.langtest.Harness": [[31, 2, 1, "", "__init__"], [31, 2, 1, "", "augment"], [31, 2, 1, "", "configure"], [31, 2, 1, "", "generate"], [31, 2, 1, "", "generated_results"], [31, 2, 1, "", "load"], [31, 2, 1, "", "report"], [31, 2, 1, "", "run"], [31, 2, 1, "", "save"], [31, 2, 1, "", "testcases"]], "langtest.testrunner": [[33, 1, 1, "", "BaseRunner"], [34, 1, 1, "", "TestRunner"]], "langtest.testrunner.BaseRunner": [[33, 2, 1, "", "__init__"], [33, 2, 1, "", "evaluate"]], "langtest.testrunner.TestRunner": [[34, 2, 1, "", "__init__"], [34, 2, 1, "", "evaluate"]], "langtest.transform": [[36, 1, 1, "", "AccuracyTestFactory"], [37, 1, 1, "", "BiasTestFactory"], [38, 1, 1, "", "FairnessTestFactory"], [39, 1, 1, "", "ITests"], [40, 1, 1, "", "RepresentationTestFactory"], [41, 1, 1, "", "RobustnessTestFactory"], [42, 1, 1, "", "TestFactory"], [43, 0, 0, "-", "accuracy"], [51, 0, 0, "-", "bias"], [57, 0, 0, "-", "fairness"], [62, 0, 0, "-", "representation"], [69, 0, 0, "-", "robustness"], [81, 0, 0, "-", "utils"]], "langtest.transform.AccuracyTestFactory": [[36, 2, 1, "", "__init__"], [36, 2, 1, "", "available_tests"], [36, 2, 1, "", "run"], [36, 2, 1, "", "transform"]], "langtest.transform.BiasTestFactory": [[37, 2, 1, "", "__init__"], [37, 2, 1, "", "available_tests"], [37, 2, 1, "", "run"], [37, 2, 1, "", "transform"]], "langtest.transform.FairnessTestFactory": [[38, 2, 1, "", "__init__"], [38, 2, 1, "", "available_tests"], [38, 2, 1, "", "run"], [38, 2, 1, "", "transform"]], "langtest.transform.ITests": [[39, 2, 1, "", "__init__"], [39, 2, 1, "", "available_tests"], [39, 2, 1, "", "run"], [39, 2, 1, "", "transform"]], "langtest.transform.RepresentationTestFactory": [[40, 2, 1, "", "__init__"], [40, 2, 1, "", "available_tests"], [40, 2, 1, "", "run"], [40, 2, 1, "", "transform"]], "langtest.transform.RobustnessTestFactory": [[41, 2, 1, "", "__init__"], [41, 2, 1, "", "available_tests"], [41, 2, 1, "", "run"], [41, 2, 1, "", "transform"]], "langtest.transform.TestFactory": [[42, 2, 1, "", "__init__"], [42, 2, 1, "", "async_run"], [42, 2, 1, "", "run"], [42, 2, 1, "", "test_categories"], [42, 2, 1, "", "test_scenarios"], [42, 2, 1, "", "transform"]], "langtest.transform.accuracy": [[44, 1, 1, "", "BaseAccuracy"], [45, 1, 1, "", "MinF1Score"], [46, 1, 1, "", "MinMacroF1Score"], [47, 1, 1, "", "MinMicroF1Score"], [48, 1, 1, "", "MinPrecisionScore"], [49, 1, 1, "", "MinRecallScore"], [50, 1, 1, "", "MinWeightedF1Score"]], "langtest.transform.accuracy.BaseAccuracy": [[44, 2, 1, "", "__init__"], [44, 3, 1, "", "alias_name"], [44, 2, 1, "", "async_run"], [44, 2, 1, "", "transform"]], "langtest.transform.accuracy.MinF1Score": [[45, 2, 1, "", "__init__"], [45, 3, 1, "", "alias_name"], [45, 2, 1, "", "async_run"], [45, 2, 1, "", "run"], [45, 2, 1, "id0", "transform"]], "langtest.transform.accuracy.MinMacroF1Score": [[46, 2, 1, "", "__init__"], [46, 3, 1, "", "alias_name"], [46, 2, 1, "", "async_run"], [46, 2, 1, "", "run"], [46, 2, 1, "id0", "transform"]], "langtest.transform.accuracy.MinMicroF1Score": [[47, 2, 1, "", "__init__"], [47, 3, 1, "", "alias_name"], [47, 2, 1, "", "async_run"], [47, 2, 1, "", "run"], [47, 2, 1, "id0", "transform"]], "langtest.transform.accuracy.MinPrecisionScore": [[48, 2, 1, "", "__init__"], [48, 3, 1, "", "alias_name"], [48, 2, 1, "", "async_run"], [48, 2, 1, "", "run"], [48, 2, 1, "id0", "transform"]], "langtest.transform.accuracy.MinRecallScore": [[49, 2, 1, "", "__init__"], [49, 3, 1, "", "alias_name"], [49, 2, 1, "", "async_run"], [49, 2, 1, "", "run"], [49, 2, 1, "id0", "transform"]], "langtest.transform.accuracy.MinWeightedF1Score": [[50, 2, 1, "", "__init__"], [50, 3, 1, "", "alias_name"], [50, 2, 1, "", "async_run"], [50, 2, 1, "", "run"], [50, 2, 1, "id0", "transform"]], "langtest.transform.bias": [[52, 1, 1, "", "BaseBias"], [53, 1, 1, "", "CountryEconomicBias"], [54, 1, 1, "", "EthnicityNameBias"], [55, 1, 1, "", "GenderPronounBias"], [56, 1, 1, "", "ReligionBias"]], "langtest.transform.bias.BaseBias": [[52, 2, 1, "", "__init__"], [52, 3, 1, "", "alias_name"], [52, 2, 1, "", "async_run"], [52, 2, 1, "", "run"], [52, 2, 1, "", "transform"]], "langtest.transform.bias.CountryEconomicBias": [[53, 2, 1, "", "__init__"], [53, 2, 1, "", "async_run"], [53, 2, 1, "", "run"], [53, 2, 1, "", "transform"]], "langtest.transform.bias.EthnicityNameBias": [[54, 2, 1, "", "__init__"], [54, 2, 1, "", "async_run"], [54, 2, 1, "", "run"], [54, 2, 1, "", "transform"]], "langtest.transform.bias.GenderPronounBias": [[55, 2, 1, "", "__init__"], [55, 2, 1, "", "async_run"], [55, 2, 1, "", "run"], [55, 2, 1, "", "transform"]], "langtest.transform.bias.ReligionBias": [[56, 2, 1, "", "__init__"], [56, 2, 1, "", "async_run"], [56, 2, 1, "", "run"], [56, 2, 1, "", "transform"]], "langtest.transform.fairness": [[58, 1, 1, "", "BaseFairness"], [59, 1, 1, "", "MaxGenderF1Score"], [60, 1, 1, "", "MinGenderF1Score"], [61, 5, 1, "", "get_gendered_data"]], "langtest.transform.fairness.BaseFairness": [[58, 2, 1, "", "__init__"], [58, 3, 1, "", "alias_name"], [58, 2, 1, "", "async_run"], [58, 2, 1, "", "transform"]], "langtest.transform.fairness.MaxGenderF1Score": [[59, 2, 1, "", "__init__"], [59, 3, 1, "", "alias_name"], [59, 2, 1, "", "async_run"], [59, 2, 1, "", "run"], [59, 2, 1, "", "transform"]], "langtest.transform.fairness.MinGenderF1Score": [[60, 2, 1, "", "__init__"], [60, 3, 1, "", "alias_name"], [60, 2, 1, "", "async_run"], [60, 2, 1, "", "run"], [60, 2, 1, "", "transform"]], "langtest.transform.representation": [[63, 1, 1, "", "BaseRepresentation"], [64, 1, 1, "", "CountryEconomicRepresentation"], [65, 1, 1, "", "EthnicityRepresentation"], [66, 1, 1, "", "GenderRepresentation"], [67, 1, 1, "", "LabelRepresentation"], [68, 1, 1, "", "ReligionRepresentation"]], "langtest.transform.representation.BaseRepresentation": [[63, 2, 1, "", "__init__"], [63, 3, 1, "", "alias_name"], [63, 2, 1, "", "async_run"], [63, 2, 1, "", "transform"]], "langtest.transform.representation.CountryEconomicRepresentation": [[64, 2, 1, "", "__init__"], [64, 3, 1, "", "alias_name"], [64, 2, 1, "", "async_run"], [64, 2, 1, "", "run"], [64, 2, 1, "", "transform"]], "langtest.transform.representation.EthnicityRepresentation": [[65, 2, 1, "", "__init__"], [65, 3, 1, "", "alias_name"], [65, 2, 1, "", "async_run"], [65, 2, 1, "", "run"], [65, 2, 1, "", "transform"]], "langtest.transform.representation.GenderRepresentation": [[66, 2, 1, "", "__init__"], [66, 3, 1, "", "alias_name"], [66, 2, 1, "", "async_run"], [66, 2, 1, "", "run"], [66, 2, 1, "", "transform"]], "langtest.transform.representation.LabelRepresentation": [[67, 2, 1, "", "__init__"], [67, 3, 1, "", "alias_name"], [67, 2, 1, "", "async_run"], [67, 2, 1, "", "run"], [67, 2, 1, "", "transform"]], "langtest.transform.representation.ReligionRepresentation": [[68, 2, 1, "", "__init__"], [68, 3, 1, "", "alias_name"], [68, 2, 1, "", "async_run"], [68, 2, 1, "", "run"], [68, 2, 1, "", "transform"]], "langtest.transform.robustness": [[70, 1, 1, "", "AddContext"], [71, 1, 1, "", "AddContraction"], [72, 1, 1, "", "AddPunctuation"], [73, 1, 1, "", "AddTypo"], [74, 1, 1, "", "BaseRobustness"], [75, 1, 1, "", "ConvertAccent"], [76, 1, 1, "", "LowerCase"], [77, 1, 1, "", "StripPunctuation"], [78, 1, 1, "", "SwapEntities"], [79, 1, 1, "", "TitleCase"], [80, 1, 1, "", "UpperCase"]], "langtest.transform.robustness.AddContext": [[70, 2, 1, "", "__init__"], [70, 2, 1, "", "async_run"], [70, 2, 1, "", "run"], [70, 2, 1, "", "transform"]], "langtest.transform.robustness.AddContraction": [[71, 2, 1, "", "__init__"], [71, 2, 1, "", "async_run"], [71, 2, 1, "", "run"], [71, 2, 1, "", "transform"]], "langtest.transform.robustness.AddPunctuation": [[72, 2, 1, "", "__init__"], [72, 2, 1, "", "async_run"], [72, 2, 1, "", "run"], [72, 2, 1, "", "transform"]], "langtest.transform.robustness.AddTypo": [[73, 2, 1, "", "__init__"], [73, 2, 1, "", "async_run"], [73, 2, 1, "", "run"], [73, 2, 1, "", "transform"]], "langtest.transform.robustness.BaseRobustness": [[74, 2, 1, "", "__init__"], [74, 3, 1, "", "alias_name"], [74, 2, 1, "", "async_run"], [74, 2, 1, "", "run"], [74, 2, 1, "", "transform"]], "langtest.transform.robustness.ConvertAccent": [[75, 2, 1, "", "__init__"], [75, 2, 1, "", "async_run"], [75, 2, 1, "", "run"], [75, 2, 1, "", "transform"]], "langtest.transform.robustness.LowerCase": [[76, 2, 1, "", "__init__"], [76, 2, 1, "", "async_run"], [76, 2, 1, "", "run"], [76, 2, 1, "", "transform"]], "langtest.transform.robustness.StripPunctuation": [[77, 2, 1, "", "__init__"], [77, 2, 1, "", "async_run"], [77, 2, 1, "", "run"], [77, 2, 1, "", "transform"]], "langtest.transform.robustness.SwapEntities": [[78, 2, 1, "", "__init__"], [78, 2, 1, "", "async_run"], [78, 2, 1, "", "run"], [78, 2, 1, "", "transform"]], "langtest.transform.robustness.TitleCase": [[79, 2, 1, "", "__init__"], [79, 2, 1, "", "async_run"], [79, 2, 1, "", "run"], [79, 2, 1, "", "transform"]], "langtest.transform.robustness.UpperCase": [[80, 2, 1, "", "__init__"], [80, 2, 1, "", "async_run"], [80, 2, 1, "", "run"], [80, 2, 1, "", "transform"]], "langtest.transform.utils": [[82, 5, 1, "", "check_name"], [83, 5, 1, "", "create_terminology"], [84, 5, 1, "", "get_country_economic_representation_dict"], [85, 5, 1, "", "get_entity_representation_proportions"], [86, 5, 1, "", "get_ethnicity_representation_dict"], [87, 5, 1, "", "get_label_representation_dict"], [88, 5, 1, "", "get_religion_name_representation_dict"], [89, 5, 1, "", "get_substitution_names"]], "langtest.utils": [[91, 0, 0, "-", "custom_types"], [111, 0, 0, "-", "gender_classifier"], [113, 0, 0, "-", "lib_manager"]], "langtest.utils.custom_types": [[92, 0, 0, "-", "helpers"], [95, 0, 0, "-", "output"], [100, 0, 0, "-", "predictions"], [103, 0, 0, "-", "sample"]], "langtest.utils.custom_types.helpers": [[93, 1, 1, "", "Span"], [94, 1, 1, "", "Transformation"]], "langtest.utils.custom_types.helpers.Span": [[93, 2, 1, "", "__init__"], [93, 2, 1, "", "construct"], [93, 2, 1, "", "copy"], [93, 2, 1, "", "dict"], [93, 2, 1, "", "json"], [93, 2, 1, "", "update_forward_refs"]], "langtest.utils.custom_types.helpers.Transformation": [[94, 2, 1, "", "__init__"], [94, 2, 1, "", "construct"], [94, 2, 1, "", "copy"], [94, 2, 1, "", "dict"], [94, 2, 1, "", "json"], [94, 2, 1, "", "update_forward_refs"]], "langtest.utils.custom_types.output": [[96, 1, 1, "", "MaxScoreOutput"], [97, 1, 1, "", "MinScoreOutput"], [98, 1, 1, "", "NEROutput"], [99, 1, 1, "", "SequenceClassificationOutput"]], "langtest.utils.custom_types.output.MaxScoreOutput": [[96, 2, 1, "", "__init__"], [96, 2, 1, "", "construct"], [96, 2, 1, "", "copy"], [96, 2, 1, "", "dict"], [96, 2, 1, "", "json"], [96, 2, 1, "", "update_forward_refs"]], "langtest.utils.custom_types.output.MinScoreOutput": [[97, 2, 1, "", "__init__"], [97, 2, 1, "", "construct"], [97, 2, 1, "", "copy"], [97, 2, 1, "", "dict"], [97, 2, 1, "", "json"], [97, 2, 1, "", "update_forward_refs"]], "langtest.utils.custom_types.output.NEROutput": [[98, 2, 1, "", "__init__"], [98, 2, 1, "", "construct"], [98, 2, 1, "", "copy"], [98, 2, 1, "", "dict"], [98, 2, 1, "", "json"], [98, 2, 1, "", "to_str_list"], [98, 2, 1, "", "update_forward_refs"]], "langtest.utils.custom_types.output.SequenceClassificationOutput": [[99, 2, 1, "", "__init__"], [99, 2, 1, "", "construct"], [99, 2, 1, "", "copy"], [99, 2, 1, "", "dict"], [99, 2, 1, "", "json"], [99, 2, 1, "", "to_str_list"], [99, 2, 1, "", "update_forward_refs"]], "langtest.utils.custom_types.predictions": [[101, 1, 1, "", "NERPrediction"], [102, 1, 1, "", "SequenceLabel"]], "langtest.utils.custom_types.predictions.NERPrediction": [[101, 2, 1, "", "__init__"], [101, 2, 1, "", "construct"], [101, 2, 1, "", "copy"], [101, 2, 1, "", "dict"], [101, 2, 1, "", "json"], [101, 2, 1, "", "update_forward_refs"]], "langtest.utils.custom_types.predictions.SequenceLabel": [[102, 2, 1, "", "__init__"], [102, 2, 1, "", "construct"], [102, 2, 1, "", "copy"], [102, 2, 1, "", "dict"], [102, 2, 1, "", "json"], [102, 2, 1, "", "update_forward_refs"]], "langtest.utils.custom_types.sample": [[104, 1, 1, "", "BaseQASample"], [105, 1, 1, "", "BaseSample"], [106, 1, 1, "", "MaxScoreSample"], [107, 1, 1, "", "MinScoreSample"], [108, 1, 1, "", "NERSample"], [109, 1, 1, "", "QASample"], [110, 1, 1, "", "SequenceClassificationSample"]], "langtest.utils.custom_types.sample.BaseQASample": [[104, 2, 1, "", "__init__"], [104, 2, 1, "", "construct"], [104, 2, 1, "", "copy"], [104, 2, 1, "", "dict"], [104, 2, 1, "", "json"], [104, 2, 1, "", "update_forward_refs"]], "langtest.utils.custom_types.sample.BaseSample": [[105, 2, 1, "", "__init__"], [105, 2, 1, "", "construct"], [105, 2, 1, "", "copy"], [105, 2, 1, "", "dict"], [105, 4, 1, "", "irrelevant_transformations"], [105, 2, 1, "", "json"], [105, 4, 1, "", "relevant_transformations"], [105, 2, 1, "", "sort_transformations"], [105, 2, 1, "", "to_dict"], [105, 2, 1, "", "update_forward_refs"]], "langtest.utils.custom_types.sample.MaxScoreSample": [[106, 2, 1, "", "__init__"], [106, 2, 1, "", "construct"], [106, 2, 1, "", "copy"], [106, 2, 1, "", "dict"], [106, 4, 1, "", "irrelevant_transformations"], [106, 2, 1, "", "json"], [106, 4, 1, "", "relevant_transformations"], [106, 2, 1, "", "sort_transformations"], [106, 2, 1, "", "to_dict"], [106, 2, 1, "", "update_forward_refs"]], "langtest.utils.custom_types.sample.MinScoreSample": [[107, 2, 1, "", "__init__"], [107, 2, 1, "", "construct"], [107, 2, 1, "", "copy"], [107, 2, 1, "", "dict"], [107, 4, 1, "", "irrelevant_transformations"], [107, 2, 1, "", "json"], [107, 4, 1, "", "relevant_transformations"], [107, 2, 1, "", "sort_transformations"], [107, 2, 1, "", "to_dict"], [107, 2, 1, "", "update_forward_refs"]], "langtest.utils.custom_types.sample.NERSample": [[108, 2, 1, "", "__init__"], [108, 2, 1, "", "construct"], [108, 2, 1, "", "copy"], [108, 2, 1, "", "dict"], [108, 2, 1, "", "get_aligned_span_pairs"], [108, 4, 1, "", "ignored_predictions"], [108, 4, 1, "", "irrelevant_transformations"], [108, 2, 1, "", "json"], [108, 4, 1, "", "realigned_spans"], [108, 4, 1, "", "relevant_transformations"], [108, 2, 1, "", "sort_transformations"], [108, 2, 1, "", "to_dict"], [108, 2, 1, "", "update_forward_refs"]], "langtest.utils.custom_types.sample.QASample": [[109, 2, 1, "", "__init__"], [109, 2, 1, "", "construct"], [109, 2, 1, "", "copy"], [109, 2, 1, "", "dict"], [109, 2, 1, "", "json"], [109, 2, 1, "", "to_dict"], [109, 2, 1, "", "update_forward_refs"]], "langtest.utils.custom_types.sample.SequenceClassificationSample": [[110, 2, 1, "", "__init__"], [110, 2, 1, "", "construct"], [110, 2, 1, "", "copy"], [110, 2, 1, "", "dict"], [110, 4, 1, "", "irrelevant_transformations"], [110, 2, 1, "", "json"], [110, 4, 1, "", "relevant_transformations"], [110, 2, 1, "", "sort_transformations"], [110, 2, 1, "", "to_dict"], [110, 2, 1, "", "update_forward_refs"]], "langtest.utils.gender_classifier": [[112, 1, 1, "", "GenderClassifier"]], "langtest.utils.gender_classifier.GenderClassifier": [[112, 2, 1, "", "__init__"], [112, 2, 1, "", "predict"]], "langtest.utils.lib_manager": [[114, 5, 1, "", "try_import_lib"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:property", "5": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "property", "Python property"], "5": ["py", "function", "Python function"]}, "titleterms": {"langtest": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114], "augment": [1, 2, 3], "augmentrobust": 2, "baseaugmentaion": 3, "datahandl": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "datasourc": [5, 6, 7, 8, 9, 10], "csvdataset": 6, "conlldataset": 7, "datafactori": 8, "jsondataset": 9, "jsonldataset": 10, "format": [11, 12, 13, 14, 15], "baseformatt": 12, "formatt": 13, "neroutputformatt": 14, "sequenceclassificationoutputformatt": 15, "modelhandl": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "jsl_modelhandl": [17, 18, 19], "pretrainedmodelforn": [18, 25, 28], "pretrainedmodelfortextclassif": [19, 26, 29], "llm_modelhandl": [20, 21], "pretrainedmodelforqa": 21, "modelfactori": 23, "spacy_modelhandl": [24, 25, 26], "transformers_modelhandl": [27, 28, 29], "har": 31, "testrunn": [32, 33, 34], "baserunn": 33, "transform": [35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 94], "accuracytestfactori": 36, "biastestfactori": 37, "fairnesstestfactori": 38, "itest": 39, "representationtestfactori": 40, "robustnesstestfactori": 41, "testfactori": 42, "accuraci": [43, 44, 45, 46, 47, 48, 49, 50], "baseaccuraci": 44, "minf1scor": 45, "minmacrof1scor": 46, "minmicrof1scor": 47, "minprecisionscor": 48, "minrecallscor": 49, "minweightedf1scor": 50, "bia": [51, 52, 53, 54, 55, 56], "basebia": 52, "countryeconomicbia": 53, "ethnicitynamebia": 54, "genderpronounbia": 55, "religionbia": 56, "fair": [57, 58, 59, 60, 61], "basefair": 58, "maxgenderf1scor": 59, "mingenderf1scor": 60, "get_gendered_data": 61, "represent": [62, 63, 64, 65, 66, 67, 68], "baserepresent": 63, "countryeconomicrepresent": 64, "ethnicityrepresent": 65, "genderrepresent": 66, "labelrepresent": 67, "religionrepresent": 68, "robust": [69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "addcontext": 70, "addcontract": 71, "addpunctu": 72, "addtypo": 73, "baserobust": 74, "convertacc": 75, "lowercas": 76, "strippunctu": 77, "swapent": 78, "titlecas": 79, "uppercas": 80, "util": [81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114], "check_nam": 82, "create_terminologi": 83, "get_country_economic_representation_dict": 84, "get_entity_representation_proport": 85, "get_ethnicity_representation_dict": 86, "get_label_representation_dict": 87, "get_religion_name_representation_dict": 88, "get_substitution_nam": 89, "custom_typ": [91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110], "helper": [92, 93, 94], "span": 93, "output": [95, 96, 97, 98, 99], "maxscoreoutput": 96, "minscoreoutput": 97, "neroutput": 98, "sequenceclassificationoutput": 99, "predict": [100, 101, 102], "nerpredict": 101, "sequencelabel": 102, "sampl": [103, 104, 105, 106, 107, 108, 109, 110], "baseqasampl": 104, "basesampl": 105, "maxscoresampl": 106, "minscoresampl": 107, "nersampl": 108, "qasampl": 109, "sequenceclassificationsampl": 110, "gender_classifi": [111, 112], "genderclassifi": 112, "lib_manag": [113, 114], "try_import_lib": 114, "nlp": [116, 117], "test": [116, 117], "document": 116, "quick": 117, "start": 117, "altern": 117, "instal": 117, "option": 117}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"langtest": [[0, "module-langtest"]], "langtest.augmentation": [[1, "module-langtest.augmentation"]], "langtest.augmentation.AugmentRobustness": [[2, "langtest-augmentation-augmentrobustness"]], "langtest.augmentation.BaseAugmentaion": [[3, "langtest-augmentation-baseaugmentaion"]], "langtest.datahandler": [[4, "module-langtest.datahandler"]], "langtest.datahandler.datasource": [[5, "module-langtest.datahandler.datasource"]], "langtest.datahandler.datasource.CSVDataset": [[6, "langtest-datahandler-datasource-csvdataset"]], "langtest.datahandler.datasource.ConllDataset": [[7, "langtest-datahandler-datasource-conlldataset"]], "langtest.datahandler.datasource.DataFactory": [[8, "langtest-datahandler-datasource-datafactory"]], "langtest.datahandler.datasource.JSONDataset": [[9, "langtest-datahandler-datasource-jsondataset"]], "langtest.datahandler.datasource.JSONLDataset": [[10, "langtest-datahandler-datasource-jsonldataset"]], "langtest.datahandler.format": [[11, "module-langtest.datahandler.format"]], "langtest.datahandler.format.BaseFormatter": [[12, "langtest-datahandler-format-baseformatter"]], "langtest.datahandler.format.Formatter": [[13, "langtest-datahandler-format-formatter"]], "langtest.datahandler.format.NEROutputFormatter": [[14, "langtest-datahandler-format-neroutputformatter"]], "langtest.datahandler.format.SequenceClassificationOutputFormatter": [[15, "langtest-datahandler-format-sequenceclassificationoutputformatter"]], "langtest.modelhandler": [[16, "module-langtest.modelhandler"]], "langtest.modelhandler.jsl_modelhandler": [[17, "module-langtest.modelhandler.jsl_modelhandler"]], "langtest.modelhandler.jsl_modelhandler.PretrainedModelForNER": [[18, "langtest-modelhandler-jsl-modelhandler-pretrainedmodelforner"]], "langtest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification": [[19, "langtest-modelhandler-jsl-modelhandler-pretrainedmodelfortextclassification"]], "langtest.modelhandler.llm_modelhandler": [[20, "module-langtest.modelhandler.llm_modelhandler"]], "langtest.modelhandler.llm_modelhandler.PretrainedModelForQA": [[21, "langtest-modelhandler-llm-modelhandler-pretrainedmodelforqa"]], "langtest.modelhandler.modelhandler": [[22, "module-langtest.modelhandler.modelhandler"]], "langtest.modelhandler.modelhandler.ModelFactory": [[23, "langtest-modelhandler-modelhandler-modelfactory"]], "langtest.modelhandler.spacy_modelhandler": [[24, "module-langtest.modelhandler.spacy_modelhandler"]], "langtest.modelhandler.spacy_modelhandler.PretrainedModelForNER": [[25, "langtest-modelhandler-spacy-modelhandler-pretrainedmodelforner"]], "langtest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification": [[26, "langtest-modelhandler-spacy-modelhandler-pretrainedmodelfortextclassification"]], "langtest.modelhandler.transformers_modelhandler": [[27, "module-langtest.modelhandler.transformers_modelhandler"]], "langtest.modelhandler.transformers_modelhandler.PretrainedModelForNER": [[28, "langtest-modelhandler-transformers-modelhandler-pretrainedmodelforner"]], "langtest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification": [[29, "langtest-modelhandler-transformers-modelhandler-pretrainedmodelfortextclassification"]], "langtest.langtest": [[30, "module-langtest.langtest"]], "langtest.langtest.Harness": [[31, "langtest-langtest-harness"]], "langtest.testrunner": [[32, "module-langtest.testrunner"]], "langtest.testrunner.BaseRunner": [[33, "langtest-testrunner-baserunner"]], "langtest.testrunner.TestRunner": [[34, "langtest-testrunner-testrunner"]], "langtest.transform": [[35, "module-langtest.transform"]], "langtest.transform.AccuracyTestFactory": [[36, "langtest-transform-accuracytestfactory"]], "langtest.transform.BiasTestFactory": [[37, "langtest-transform-biastestfactory"]], "langtest.transform.FairnessTestFactory": [[38, "langtest-transform-fairnesstestfactory"]], "langtest.transform.ITests": [[39, "langtest-transform-itests"]], "langtest.transform.RepresentationTestFactory": [[40, "langtest-transform-representationtestfactory"]], "langtest.transform.RobustnessTestFactory": [[41, "langtest-transform-robustnesstestfactory"]], "langtest.transform.TestFactory": [[42, "langtest-transform-testfactory"]], "langtest.transform.accuracy": [[43, "module-langtest.transform.accuracy"]], "langtest.transform.accuracy.BaseAccuracy": [[44, "langtest-transform-accuracy-baseaccuracy"]], "langtest.transform.accuracy.MinF1Score": [[45, "langtest-transform-accuracy-minf1score"]], "langtest.transform.accuracy.MinMacroF1Score": [[46, "langtest-transform-accuracy-minmacrof1score"]], "langtest.transform.accuracy.MinMicroF1Score": [[47, "langtest-transform-accuracy-minmicrof1score"]], "langtest.transform.accuracy.MinPrecisionScore": [[48, "langtest-transform-accuracy-minprecisionscore"]], "langtest.transform.accuracy.MinRecallScore": [[49, "langtest-transform-accuracy-minrecallscore"]], "langtest.transform.accuracy.MinWeightedF1Score": [[50, "langtest-transform-accuracy-minweightedf1score"]], "langtest.transform.bias": [[51, "module-langtest.transform.bias"]], "langtest.transform.bias.BaseBias": [[52, "langtest-transform-bias-basebias"]], "langtest.transform.bias.CountryEconomicBias": [[53, "langtest-transform-bias-countryeconomicbias"]], "langtest.transform.bias.EthnicityNameBias": [[54, "langtest-transform-bias-ethnicitynamebias"]], "langtest.transform.bias.GenderPronounBias": [[55, "langtest-transform-bias-genderpronounbias"]], "langtest.transform.bias.ReligionBias": [[56, "langtest-transform-bias-religionbias"]], "langtest.transform.fairness": [[57, "module-langtest.transform.fairness"]], "langtest.transform.fairness.BaseFairness": [[58, "langtest-transform-fairness-basefairness"]], "langtest.transform.fairness.MaxGenderF1Score": [[59, "langtest-transform-fairness-maxgenderf1score"]], "langtest.transform.fairness.MinGenderF1Score": [[60, "langtest-transform-fairness-mingenderf1score"]], "langtest.transform.fairness.get_gendered_data": [[61, "langtest-transform-fairness-get-gendered-data"]], "langtest.transform.representation": [[62, "module-langtest.transform.representation"]], "langtest.transform.representation.BaseRepresentation": [[63, "langtest-transform-representation-baserepresentation"]], "langtest.transform.representation.CountryEconomicRepresentation": [[64, "langtest-transform-representation-countryeconomicrepresentation"]], "langtest.transform.representation.EthnicityRepresentation": [[65, "langtest-transform-representation-ethnicityrepresentation"]], "langtest.transform.representation.GenderRepresentation": [[66, "langtest-transform-representation-genderrepresentation"]], "langtest.transform.representation.LabelRepresentation": [[67, "langtest-transform-representation-labelrepresentation"]], "langtest.transform.representation.ReligionRepresentation": [[68, "langtest-transform-representation-religionrepresentation"]], "langtest.transform.robustness": [[69, "module-langtest.transform.robustness"]], "langtest.transform.robustness.AddContext": [[70, "langtest-transform-robustness-addcontext"]], "langtest.transform.robustness.AddContraction": [[71, "langtest-transform-robustness-addcontraction"]], "langtest.transform.robustness.AddPunctuation": [[72, "langtest-transform-robustness-addpunctuation"]], "langtest.transform.robustness.AddTypo": [[73, "langtest-transform-robustness-addtypo"]], "langtest.transform.robustness.BaseRobustness": [[74, "langtest-transform-robustness-baserobustness"]], "langtest.transform.robustness.ConvertAccent": [[75, "langtest-transform-robustness-convertaccent"]], "langtest.transform.robustness.LowerCase": [[76, "langtest-transform-robustness-lowercase"]], "langtest.transform.robustness.StripPunctuation": [[77, "langtest-transform-robustness-strippunctuation"]], "langtest.transform.robustness.SwapEntities": [[78, "langtest-transform-robustness-swapentities"]], "langtest.transform.robustness.TitleCase": [[79, "langtest-transform-robustness-titlecase"]], "langtest.transform.robustness.UpperCase": [[80, "langtest-transform-robustness-uppercase"]], "langtest.transform.utils": [[81, "module-langtest.transform.utils"]], "langtest.transform.utils.check_name": [[82, "langtest-transform-utils-check-name"]], "langtest.transform.utils.create_terminology": [[83, "langtest-transform-utils-create-terminology"]], "langtest.transform.utils.get_country_economic_representation_dict": [[84, "langtest-transform-utils-get-country-economic-representation-dict"]], "langtest.transform.utils.get_entity_representation_proportions": [[85, "langtest-transform-utils-get-entity-representation-proportions"]], "langtest.transform.utils.get_ethnicity_representation_dict": [[86, "langtest-transform-utils-get-ethnicity-representation-dict"]], "langtest.transform.utils.get_label_representation_dict": [[87, "langtest-transform-utils-get-label-representation-dict"]], "langtest.transform.utils.get_religion_name_representation_dict": [[88, "langtest-transform-utils-get-religion-name-representation-dict"]], "langtest.transform.utils.get_substitution_names": [[89, "langtest-transform-utils-get-substitution-names"]], "langtest.utils": [[90, "module-langtest.utils"]], "langtest.utils.custom_types": [[91, "module-langtest.utils.custom_types"]], "langtest.utils.custom_types.helpers": [[92, "module-langtest.utils.custom_types.helpers"]], "langtest.utils.custom_types.helpers.Span": [[93, "langtest-utils-custom-types-helpers-span"]], "langtest.utils.custom_types.helpers.Transformation": [[94, "langtest-utils-custom-types-helpers-transformation"]], "langtest.utils.custom_types.output": [[95, "module-langtest.utils.custom_types.output"]], "langtest.utils.custom_types.output.MaxScoreOutput": [[96, "langtest-utils-custom-types-output-maxscoreoutput"]], "langtest.utils.custom_types.output.MinScoreOutput": [[97, "langtest-utils-custom-types-output-minscoreoutput"]], "langtest.utils.custom_types.output.NEROutput": [[98, "langtest-utils-custom-types-output-neroutput"]], "langtest.utils.custom_types.output.SequenceClassificationOutput": [[99, "langtest-utils-custom-types-output-sequenceclassificationoutput"]], "langtest.utils.custom_types.predictions": [[100, "module-langtest.utils.custom_types.predictions"]], "langtest.utils.custom_types.predictions.NERPrediction": [[101, "langtest-utils-custom-types-predictions-nerprediction"]], "langtest.utils.custom_types.predictions.SequenceLabel": [[102, "langtest-utils-custom-types-predictions-sequencelabel"]], "langtest.utils.custom_types.sample": [[103, "module-langtest.utils.custom_types.sample"]], "langtest.utils.custom_types.sample.BaseQASample": [[104, "langtest-utils-custom-types-sample-baseqasample"]], "langtest.utils.custom_types.sample.BaseSample": [[105, "langtest-utils-custom-types-sample-basesample"]], "langtest.utils.custom_types.sample.MaxScoreSample": [[106, "langtest-utils-custom-types-sample-maxscoresample"]], "langtest.utils.custom_types.sample.MinScoreSample": [[107, "langtest-utils-custom-types-sample-minscoresample"]], "langtest.utils.custom_types.sample.NERSample": [[108, "langtest-utils-custom-types-sample-nersample"]], "langtest.utils.custom_types.sample.QASample": [[109, "langtest-utils-custom-types-sample-qasample"]], "langtest.utils.custom_types.sample.SequenceClassificationSample": [[110, "langtest-utils-custom-types-sample-sequenceclassificationsample"]], "langtest.utils.gender_classifier": [[111, "module-langtest.utils.gender_classifier"]], "langtest.utils.gender_classifier.GenderClassifier": [[112, "langtest-utils-gender-classifier-genderclassifier"]], "langtest.utils.lib_manager": [[113, "module-langtest.utils.lib_manager"]], "langtest.utils.lib_manager.try_import_lib": [[114, "langtest-utils-lib-manager-try-import-lib"]], "LangTest Documentation": [[116, "nlp-test-documentation"]], "Quick Start": [[117, "quick-start"]], "LangTest Quick Start": [[117, "nlp-test-quick-start"]], "Alternative Installation Options": [[117, "alternative-installation-options"]]}, "indexentries": {"module": [[0, "module-langtest"], [1, "module-langtest.augmentation"], [4, "module-langtest.datahandler"], [5, "module-langtest.datahandler.datasource"], [11, "module-langtest.datahandler.format"], [16, "module-langtest.modelhandler"], [17, "module-langtest.modelhandler.jsl_modelhandler"], [20, "module-langtest.modelhandler.llm_modelhandler"], [22, "module-langtest.modelhandler.modelhandler"], [24, "module-langtest.modelhandler.spacy_modelhandler"], [27, "module-langtest.modelhandler.transformers_modelhandler"], [30, "module-langtest.langtest"], [32, "module-langtest.testrunner"], [35, "module-langtest.transform"], [43, "module-langtest.transform.accuracy"], [51, "module-langtest.transform.bias"], [57, "module-langtest.transform.fairness"], [62, "module-langtest.transform.representation"], [69, "module-langtest.transform.robustness"], [81, "module-langtest.transform.utils"], [90, "module-langtest.utils"], [91, "module-langtest.utils.custom_types"], [92, "module-langtest.utils.custom_types.helpers"], [95, "module-langtest.utils.custom_types.output"], [100, "module-langtest.utils.custom_types.predictions"], [103, "module-langtest.utils.custom_types.sample"], [111, "module-langtest.utils.gender_classifier"], [113, "module-langtest.utils.lib_manager"]], "langtest": [[0, "module-langtest"]], "langtest.augmentation": [[1, "module-langtest.augmentation"]], "augmentrobustness (class in langtest.augmentation)": [[2, "langtest.augmentation.AugmentRobustness"]], "__init__() (augmentrobustness method)": [[2, "id0"], [2, "langtest.augmentation.AugmentRobustness.__init__"]], "config (augmentrobustness attribute)": [[2, "langtest.augmentation.AugmentRobustness.config"]], "fix() (augmentrobustness method)": [[2, "id1"], [2, "langtest.augmentation.AugmentRobustness.fix"]], "h_report (augmentrobustness attribute)": [[2, "langtest.augmentation.AugmentRobustness.h_report"]], "max_prop (augmentrobustness attribute)": [[2, "langtest.augmentation.AugmentRobustness.max_prop"]], "suggestions() (augmentrobustness method)": [[2, "id2"], [2, "langtest.augmentation.AugmentRobustness.suggestions"]], "task (augmentrobustness attribute)": [[2, "langtest.augmentation.AugmentRobustness.task"]], "baseaugmentaion (class in langtest.augmentation)": [[3, "langtest.augmentation.BaseAugmentaion"]], "none (baseaugmentaion attribute)": [[3, "langtest.augmentation.BaseAugmentaion.None"]], "__init__() (baseaugmentaion method)": [[3, "langtest.augmentation.BaseAugmentaion.__init__"]], "fix() (baseaugmentaion method)": [[3, "id0"], [3, "langtest.augmentation.BaseAugmentaion.fix"]], "langtest.datahandler": [[4, "module-langtest.datahandler"]], "langtest.datahandler.datasource": [[5, "module-langtest.datahandler.datasource"]], "csvdataset (class in langtest.datahandler.datasource)": [[6, "langtest.datahandler.datasource.CSVDataset"]], "__init__() (csvdataset method)": [[6, "langtest.datahandler.datasource.CSVDataset.__init__"]], "export_data() (csvdataset method)": [[6, "langtest.datahandler.datasource.CSVDataset.export_data"]], "load_data() (csvdataset method)": [[6, "langtest.datahandler.datasource.CSVDataset.load_data"]], "conlldataset (class in langtest.datahandler.datasource)": [[7, "langtest.datahandler.datasource.ConllDataset"]], "__init__() (conlldataset method)": [[7, "langtest.datahandler.datasource.ConllDataset.__init__"]], "export_data() (conlldataset method)": [[7, "langtest.datahandler.datasource.ConllDataset.export_data"]], "load_data() (conlldataset method)": [[7, "langtest.datahandler.datasource.ConllDataset.load_data"]], "datafactory (class in langtest.datahandler.datasource)": [[8, "langtest.datahandler.datasource.DataFactory"]], "__init__() (datafactory method)": [[8, "langtest.datahandler.datasource.DataFactory.__init__"]], "export() (datafactory method)": [[8, "langtest.datahandler.datasource.DataFactory.export"]], "load() (datafactory method)": [[8, "langtest.datahandler.datasource.DataFactory.load"]], "jsondataset (class in langtest.datahandler.datasource)": [[9, "langtest.datahandler.datasource.JSONDataset"]], "__init__() (jsondataset method)": [[9, "langtest.datahandler.datasource.JSONDataset.__init__"]], "export_data() (jsondataset method)": [[9, "langtest.datahandler.datasource.JSONDataset.export_data"]], "jsonldataset (class in langtest.datahandler.datasource)": [[10, "langtest.datahandler.datasource.JSONLDataset"]], "__init__() (jsonldataset method)": [[10, "langtest.datahandler.datasource.JSONLDataset.__init__"]], "export_data() (jsonldataset method)": [[10, "langtest.datahandler.datasource.JSONLDataset.export_data"]], "load_data() (jsonldataset method)": [[10, "langtest.datahandler.datasource.JSONLDataset.load_data"]], "langtest.datahandler.format": [[11, "module-langtest.datahandler.format"]], "baseformatter (class in langtest.datahandler.format)": [[12, "langtest.datahandler.format.BaseFormatter"]], "__init__() (baseformatter method)": [[12, "langtest.datahandler.format.BaseFormatter.__init__"]], "to_conll() (baseformatter static method)": [[12, "langtest.datahandler.format.BaseFormatter.to_conll"]], "to_csv() (baseformatter static method)": [[12, "langtest.datahandler.format.BaseFormatter.to_csv"]], "formatter (class in langtest.datahandler.format)": [[13, "langtest.datahandler.format.Formatter"]], "__init__() (formatter method)": [[13, "langtest.datahandler.format.Formatter.__init__"]], "process() (formatter static method)": [[13, "langtest.datahandler.format.Formatter.process"]], "neroutputformatter (class in langtest.datahandler.format)": [[14, "langtest.datahandler.format.NEROutputFormatter"]], "__init__() (neroutputformatter method)": [[14, "langtest.datahandler.format.NEROutputFormatter.__init__"]], "to_conll() (neroutputformatter static method)": [[14, "langtest.datahandler.format.NEROutputFormatter.to_conll"]], "to_csv() (neroutputformatter static method)": [[14, "langtest.datahandler.format.NEROutputFormatter.to_csv"]], "sequenceclassificationoutputformatter (class in langtest.datahandler.format)": [[15, "langtest.datahandler.format.SequenceClassificationOutputFormatter"]], "__init__() (sequenceclassificationoutputformatter method)": [[15, "langtest.datahandler.format.SequenceClassificationOutputFormatter.__init__"]], "to_conll() (sequenceclassificationoutputformatter static method)": [[15, "langtest.datahandler.format.SequenceClassificationOutputFormatter.to_conll"]], "to_csv() (sequenceclassificationoutputformatter static method)": [[15, "langtest.datahandler.format.SequenceClassificationOutputFormatter.to_csv"]], "langtest.modelhandler": [[16, "module-langtest.modelhandler"]], "langtest.modelhandler.jsl_modelhandler": [[17, "module-langtest.modelhandler.jsl_modelhandler"]], "pretrainedmodelforner (class in langtest.modelhandler.jsl_modelhandler)": [[18, "langtest.modelhandler.jsl_modelhandler.PretrainedModelForNER"]], "__init__() (pretrainedmodelforner method)": [[18, "langtest.modelhandler.jsl_modelhandler.PretrainedModelForNER.__init__"], [25, "langtest.modelhandler.spacy_modelhandler.PretrainedModelForNER.__init__"], [28, "langtest.modelhandler.transformers_modelhandler.PretrainedModelForNER.__init__"]], "group_entities() (pretrainedmodelforner method)": [[18, "langtest.modelhandler.jsl_modelhandler.PretrainedModelForNER.group_entities"], [28, "langtest.modelhandler.transformers_modelhandler.PretrainedModelForNER.group_entities"]], "is_ner_annotator() (pretrainedmodelforner static method)": [[18, "langtest.modelhandler.jsl_modelhandler.PretrainedModelForNER.is_ner_annotator"]], "load_model() (pretrainedmodelforner class method)": [[18, "langtest.modelhandler.jsl_modelhandler.PretrainedModelForNER.load_model"], [25, "langtest.modelhandler.spacy_modelhandler.PretrainedModelForNER.load_model"], [28, "langtest.modelhandler.transformers_modelhandler.PretrainedModelForNER.load_model"]], "model (pretrainedmodelforner attribute)": [[18, "id0"], [18, "langtest.modelhandler.jsl_modelhandler.PretrainedModelForNER.model"], [28, "id0"], [28, "langtest.modelhandler.transformers_modelhandler.PretrainedModelForNER.model"]], "predict() (pretrainedmodelforner method)": [[18, "langtest.modelhandler.jsl_modelhandler.PretrainedModelForNER.predict"], [25, "langtest.modelhandler.spacy_modelhandler.PretrainedModelForNER.predict"], [28, "langtest.modelhandler.transformers_modelhandler.PretrainedModelForNER.predict"]], "predict_raw() (pretrainedmodelforner method)": [[18, "langtest.modelhandler.jsl_modelhandler.PretrainedModelForNER.predict_raw"], [25, "langtest.modelhandler.spacy_modelhandler.PretrainedModelForNER.predict_raw"], [28, "langtest.modelhandler.transformers_modelhandler.PretrainedModelForNER.predict_raw"]], "pretrainedmodelfortextclassification (class in langtest.modelhandler.jsl_modelhandler)": [[19, "langtest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification"]], "__init__() (pretrainedmodelfortextclassification method)": [[19, "langtest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification.__init__"], [26, "langtest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification.__init__"], [29, "langtest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification.__init__"]], "is_classifier() (pretrainedmodelfortextclassification static method)": [[19, "langtest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification.is_classifier"]], "load_model() (pretrainedmodelfortextclassification class method)": [[19, "langtest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification.load_model"], [26, "langtest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification.load_model"], [29, "langtest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification.load_model"]], "model (pretrainedmodelfortextclassification attribute)": [[19, "id0"], [19, "langtest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification.model"], [29, "langtest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification.model"]], "predict() (pretrainedmodelfortextclassification method)": [[19, "langtest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification.predict"], [26, "langtest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification.predict"], [29, "langtest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification.predict"]], "predict_raw() (pretrainedmodelfortextclassification method)": [[19, "langtest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification.predict_raw"], [26, "langtest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification.predict_raw"], [29, "langtest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification.predict_raw"]], "langtest.modelhandler.llm_modelhandler": [[20, "module-langtest.modelhandler.llm_modelhandler"]], "pretrainedmodelforqa (class in langtest.modelhandler.llm_modelhandler)": [[21, "langtest.modelhandler.llm_modelhandler.PretrainedModelForQA"]], "__init__() (pretrainedmodelforqa method)": [[21, "langtest.modelhandler.llm_modelhandler.PretrainedModelForQA.__init__"]], "predict() (pretrainedmodelforqa method)": [[21, "langtest.modelhandler.llm_modelhandler.PretrainedModelForQA.predict"]], "langtest.modelhandler.modelhandler": [[22, "module-langtest.modelhandler.modelhandler"]], "modelfactory (class in langtest.modelhandler.modelhandler)": [[23, "langtest.modelhandler.modelhandler.ModelFactory"]], "__init__() (modelfactory method)": [[23, "langtest.modelhandler.modelhandler.ModelFactory.__init__"]], "load_model() (modelfactory class method)": [[23, "langtest.modelhandler.modelhandler.ModelFactory.load_model"]], "predict() (modelfactory method)": [[23, "langtest.modelhandler.modelhandler.ModelFactory.predict"]], "predict_raw() (modelfactory method)": [[23, "langtest.modelhandler.modelhandler.ModelFactory.predict_raw"]], "langtest.modelhandler.spacy_modelhandler": [[24, "module-langtest.modelhandler.spacy_modelhandler"]], "pretrainedmodelforner (class in langtest.modelhandler.spacy_modelhandler)": [[25, "langtest.modelhandler.spacy_modelhandler.PretrainedModelForNER"]], "pretrainedmodelfortextclassification (class in langtest.modelhandler.spacy_modelhandler)": [[26, "langtest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification"]], "labels (pretrainedmodelfortextclassification property)": [[26, "langtest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification.labels"], [29, "langtest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification.labels"]], "model (in module langtest.modelhandler.transformers_modelhandler)": [[27, "langtest.modelhandler.transformers_modelhandler.model"]], "langtest.modelhandler.transformers_modelhandler": [[27, "module-langtest.modelhandler.transformers_modelhandler"]], "pretrainedmodelforner (class in langtest.modelhandler.transformers_modelhandler)": [[28, "langtest.modelhandler.transformers_modelhandler.PretrainedModelForNER"]], "pretrainedmodelfortextclassification (class in langtest.modelhandler.transformers_modelhandler)": [[29, "langtest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification"]], "langtest.langtest": [[30, "module-langtest.langtest"]], "harness (class in langtest.langtest)": [[31, "langtest.langtest.Harness"]], "__init__() (harness method)": [[31, "langtest.langtest.Harness.__init__"]], "augment() (harness method)": [[31, "langtest.langtest.Harness.augment"]], "configure() (harness method)": [[31, "langtest.langtest.Harness.configure"]], "generate() (harness method)": [[31, "langtest.langtest.Harness.generate"]], "generated_results() (harness method)": [[31, "langtest.langtest.Harness.generated_results"]], "load() (harness class method)": [[31, "langtest.langtest.Harness.load"]], "report() (harness method)": [[31, "langtest.langtest.Harness.report"]], "run() (harness method)": [[31, "langtest.langtest.Harness.run"]], "save() (harness method)": [[31, "langtest.langtest.Harness.save"]], "testcases() (harness method)": [[31, "langtest.langtest.Harness.testcases"]], "langtest.testrunner": [[32, "module-langtest.testrunner"]], "baserunner (class in langtest.testrunner)": [[33, "langtest.testrunner.BaseRunner"]], "__init__() (baserunner method)": [[33, "langtest.testrunner.BaseRunner.__init__"]], "evaluate() (baserunner method)": [[33, "langtest.testrunner.BaseRunner.evaluate"]], "testrunner (class in langtest.testrunner)": [[34, "langtest.testrunner.TestRunner"]], "__init__() (testrunner method)": [[34, "langtest.testrunner.TestRunner.__init__"]], "evaluate() (testrunner method)": [[34, "langtest.testrunner.TestRunner.evaluate"]], "langtest.transform": [[35, "module-langtest.transform"]], "accuracytestfactory (class in langtest.transform)": [[36, "langtest.transform.AccuracyTestFactory"]], "__init__() (accuracytestfactory method)": [[36, "langtest.transform.AccuracyTestFactory.__init__"]], "available_tests() (accuracytestfactory class method)": [[36, "langtest.transform.AccuracyTestFactory.available_tests"]], "run() (accuracytestfactory class method)": [[36, "langtest.transform.AccuracyTestFactory.run"]], "transform() (accuracytestfactory method)": [[36, "langtest.transform.AccuracyTestFactory.transform"]], "biastestfactory (class in langtest.transform)": [[37, "langtest.transform.BiasTestFactory"]], "__init__() (biastestfactory method)": [[37, "langtest.transform.BiasTestFactory.__init__"]], "available_tests() (biastestfactory class method)": [[37, "langtest.transform.BiasTestFactory.available_tests"]], "run() (biastestfactory class method)": [[37, "langtest.transform.BiasTestFactory.run"]], "transform() (biastestfactory method)": [[37, "langtest.transform.BiasTestFactory.transform"]], "fairnesstestfactory (class in langtest.transform)": [[38, "langtest.transform.FairnessTestFactory"]], "__init__() (fairnesstestfactory method)": [[38, "langtest.transform.FairnessTestFactory.__init__"]], "available_tests() (fairnesstestfactory class method)": [[38, "langtest.transform.FairnessTestFactory.available_tests"]], "run() (fairnesstestfactory class method)": [[38, "langtest.transform.FairnessTestFactory.run"]], "transform() (fairnesstestfactory method)": [[38, "langtest.transform.FairnessTestFactory.transform"]], "itests (class in langtest.transform)": [[39, "langtest.transform.ITests"]], "__init__() (itests method)": [[39, "langtest.transform.ITests.__init__"]], "available_tests() (itests method)": [[39, "langtest.transform.ITests.available_tests"]], "run() (itests class method)": [[39, "langtest.transform.ITests.run"]], "transform() (itests method)": [[39, "langtest.transform.ITests.transform"]], "representationtestfactory (class in langtest.transform)": [[40, "langtest.transform.RepresentationTestFactory"]], "__init__() (representationtestfactory method)": [[40, "langtest.transform.RepresentationTestFactory.__init__"]], "available_tests() (representationtestfactory class method)": [[40, "langtest.transform.RepresentationTestFactory.available_tests"]], "run() (representationtestfactory class method)": [[40, "langtest.transform.RepresentationTestFactory.run"]], "transform() (representationtestfactory method)": [[40, "langtest.transform.RepresentationTestFactory.transform"]], "robustnesstestfactory (class in langtest.transform)": [[41, "langtest.transform.RobustnessTestFactory"]], "__init__() (robustnesstestfactory method)": [[41, "langtest.transform.RobustnessTestFactory.__init__"]], "available_tests() (robustnesstestfactory class method)": [[41, "langtest.transform.RobustnessTestFactory.available_tests"]], "run() (robustnesstestfactory class method)": [[41, "langtest.transform.RobustnessTestFactory.run"]], "transform() (robustnesstestfactory method)": [[41, "langtest.transform.RobustnessTestFactory.transform"]], "testfactory (class in langtest.transform)": [[42, "langtest.transform.TestFactory"]], "__init__() (testfactory method)": [[42, "langtest.transform.TestFactory.__init__"]], "async_run() (testfactory class method)": [[42, "langtest.transform.TestFactory.async_run"]], "run() (testfactory static method)": [[42, "langtest.transform.TestFactory.run"]], "test_categories() (testfactory class method)": [[42, "langtest.transform.TestFactory.test_categories"]], "test_scenarios() (testfactory class method)": [[42, "langtest.transform.TestFactory.test_scenarios"]], "transform() (testfactory static method)": [[42, "langtest.transform.TestFactory.transform"]], "langtest.transform.accuracy": [[43, "module-langtest.transform.accuracy"]], "baseaccuracy (class in langtest.transform.accuracy)": [[44, "langtest.transform.accuracy.BaseAccuracy"]], "__init__() (baseaccuracy method)": [[44, "langtest.transform.accuracy.BaseAccuracy.__init__"]], "alias_name (baseaccuracy attribute)": [[44, "langtest.transform.accuracy.BaseAccuracy.alias_name"]], "async_run() (baseaccuracy class method)": [[44, "langtest.transform.accuracy.BaseAccuracy.async_run"]], "transform() (baseaccuracy static method)": [[44, "langtest.transform.accuracy.BaseAccuracy.transform"]], "minf1score (class in langtest.transform.accuracy)": [[45, "langtest.transform.accuracy.MinF1Score"]], "__init__() (minf1score method)": [[45, "langtest.transform.accuracy.MinF1Score.__init__"]], "alias_name (minf1score attribute)": [[45, "langtest.transform.accuracy.MinF1Score.alias_name"]], "async_run() (minf1score class method)": [[45, "langtest.transform.accuracy.MinF1Score.async_run"]], "run() (minf1score method)": [[45, "langtest.transform.accuracy.MinF1Score.run"]], "transform() (minf1score method)": [[45, "langtest.transform.accuracy.MinF1Score.transform"]], "transform() (minf1score static method)": [[45, "id0"]], "minmacrof1score (class in langtest.transform.accuracy)": [[46, "langtest.transform.accuracy.MinMacroF1Score"]], "__init__() (minmacrof1score method)": [[46, "langtest.transform.accuracy.MinMacroF1Score.__init__"]], "alias_name (minmacrof1score attribute)": [[46, "langtest.transform.accuracy.MinMacroF1Score.alias_name"]], "async_run() (minmacrof1score class method)": [[46, "langtest.transform.accuracy.MinMacroF1Score.async_run"]], "run() (minmacrof1score method)": [[46, "langtest.transform.accuracy.MinMacroF1Score.run"]], "transform() (minmacrof1score method)": [[46, "langtest.transform.accuracy.MinMacroF1Score.transform"]], "transform() (minmacrof1score static method)": [[46, "id0"]], "minmicrof1score (class in langtest.transform.accuracy)": [[47, "langtest.transform.accuracy.MinMicroF1Score"]], "__init__() (minmicrof1score method)": [[47, "langtest.transform.accuracy.MinMicroF1Score.__init__"]], "alias_name (minmicrof1score attribute)": [[47, "langtest.transform.accuracy.MinMicroF1Score.alias_name"]], "async_run() (minmicrof1score class method)": [[47, "langtest.transform.accuracy.MinMicroF1Score.async_run"]], "run() (minmicrof1score method)": [[47, "langtest.transform.accuracy.MinMicroF1Score.run"]], "transform() (minmicrof1score method)": [[47, "langtest.transform.accuracy.MinMicroF1Score.transform"]], "transform() (minmicrof1score static method)": [[47, "id0"]], "minprecisionscore (class in langtest.transform.accuracy)": [[48, "langtest.transform.accuracy.MinPrecisionScore"]], "__init__() (minprecisionscore method)": [[48, "langtest.transform.accuracy.MinPrecisionScore.__init__"]], "alias_name (minprecisionscore attribute)": [[48, "langtest.transform.accuracy.MinPrecisionScore.alias_name"]], "async_run() (minprecisionscore class method)": [[48, "langtest.transform.accuracy.MinPrecisionScore.async_run"]], "run() (minprecisionscore method)": [[48, "langtest.transform.accuracy.MinPrecisionScore.run"]], "transform() (minprecisionscore method)": [[48, "langtest.transform.accuracy.MinPrecisionScore.transform"]], "transform() (minprecisionscore static method)": [[48, "id0"]], "minrecallscore (class in langtest.transform.accuracy)": [[49, "langtest.transform.accuracy.MinRecallScore"]], "__init__() (minrecallscore method)": [[49, "langtest.transform.accuracy.MinRecallScore.__init__"]], "alias_name (minrecallscore attribute)": [[49, "langtest.transform.accuracy.MinRecallScore.alias_name"]], "async_run() (minrecallscore class method)": [[49, "langtest.transform.accuracy.MinRecallScore.async_run"]], "run() (minrecallscore method)": [[49, "langtest.transform.accuracy.MinRecallScore.run"]], "transform() (minrecallscore method)": [[49, "langtest.transform.accuracy.MinRecallScore.transform"]], "transform() (minrecallscore static method)": [[49, "id0"]], "minweightedf1score (class in langtest.transform.accuracy)": [[50, "langtest.transform.accuracy.MinWeightedF1Score"]], "__init__() (minweightedf1score method)": [[50, "langtest.transform.accuracy.MinWeightedF1Score.__init__"]], "alias_name (minweightedf1score attribute)": [[50, "langtest.transform.accuracy.MinWeightedF1Score.alias_name"]], "async_run() (minweightedf1score class method)": [[50, "langtest.transform.accuracy.MinWeightedF1Score.async_run"]], "run() (minweightedf1score method)": [[50, "langtest.transform.accuracy.MinWeightedF1Score.run"]], "transform() (minweightedf1score method)": [[50, "langtest.transform.accuracy.MinWeightedF1Score.transform"]], "transform() (minweightedf1score static method)": [[50, "id0"]], "langtest.transform.bias": [[51, "module-langtest.transform.bias"]], "basebias (class in langtest.transform.bias)": [[52, "langtest.transform.bias.BaseBias"]], "__init__() (basebias method)": [[52, "langtest.transform.bias.BaseBias.__init__"]], "alias_name (basebias attribute)": [[52, "langtest.transform.bias.BaseBias.alias_name"]], "async_run() (basebias class method)": [[52, "langtest.transform.bias.BaseBias.async_run"]], "run() (basebias static method)": [[52, "langtest.transform.bias.BaseBias.run"]], "transform() (basebias method)": [[52, "langtest.transform.bias.BaseBias.transform"]], "countryeconomicbias (class in langtest.transform.bias)": [[53, "langtest.transform.bias.CountryEconomicBias"]], "__init__() (countryeconomicbias method)": [[53, "langtest.transform.bias.CountryEconomicBias.__init__"]], "async_run() (countryeconomicbias class method)": [[53, "langtest.transform.bias.CountryEconomicBias.async_run"]], "run() (countryeconomicbias static method)": [[53, "langtest.transform.bias.CountryEconomicBias.run"]], "transform() (countryeconomicbias static method)": [[53, "langtest.transform.bias.CountryEconomicBias.transform"]], "ethnicitynamebias (class in langtest.transform.bias)": [[54, "langtest.transform.bias.EthnicityNameBias"]], "__init__() (ethnicitynamebias method)": [[54, "langtest.transform.bias.EthnicityNameBias.__init__"]], "async_run() (ethnicitynamebias class method)": [[54, "langtest.transform.bias.EthnicityNameBias.async_run"]], "run() (ethnicitynamebias static method)": [[54, "langtest.transform.bias.EthnicityNameBias.run"]], "transform() (ethnicitynamebias static method)": [[54, "langtest.transform.bias.EthnicityNameBias.transform"]], "genderpronounbias (class in langtest.transform.bias)": [[55, "langtest.transform.bias.GenderPronounBias"]], "__init__() (genderpronounbias method)": [[55, "langtest.transform.bias.GenderPronounBias.__init__"]], "async_run() (genderpronounbias class method)": [[55, "langtest.transform.bias.GenderPronounBias.async_run"]], "run() (genderpronounbias static method)": [[55, "langtest.transform.bias.GenderPronounBias.run"]], "transform() (genderpronounbias static method)": [[55, "langtest.transform.bias.GenderPronounBias.transform"]], "religionbias (class in langtest.transform.bias)": [[56, "langtest.transform.bias.ReligionBias"]], "__init__() (religionbias method)": [[56, "langtest.transform.bias.ReligionBias.__init__"]], "async_run() (religionbias class method)": [[56, "langtest.transform.bias.ReligionBias.async_run"]], "run() (religionbias static method)": [[56, "langtest.transform.bias.ReligionBias.run"]], "transform() (religionbias static method)": [[56, "langtest.transform.bias.ReligionBias.transform"]], "langtest.transform.fairness": [[57, "module-langtest.transform.fairness"]], "basefairness (class in langtest.transform.fairness)": [[58, "langtest.transform.fairness.BaseFairness"]], "__init__() (basefairness method)": [[58, "langtest.transform.fairness.BaseFairness.__init__"]], "alias_name (basefairness attribute)": [[58, "langtest.transform.fairness.BaseFairness.alias_name"]], "async_run() (basefairness class method)": [[58, "langtest.transform.fairness.BaseFairness.async_run"]], "transform() (basefairness static method)": [[58, "langtest.transform.fairness.BaseFairness.transform"]], "maxgenderf1score (class in langtest.transform.fairness)": [[59, "langtest.transform.fairness.MaxGenderF1Score"]], "__init__() (maxgenderf1score method)": [[59, "langtest.transform.fairness.MaxGenderF1Score.__init__"]], "alias_name (maxgenderf1score attribute)": [[59, "langtest.transform.fairness.MaxGenderF1Score.alias_name"]], "async_run() (maxgenderf1score class method)": [[59, "langtest.transform.fairness.MaxGenderF1Score.async_run"]], "run() (maxgenderf1score method)": [[59, "langtest.transform.fairness.MaxGenderF1Score.run"]], "transform() (maxgenderf1score static method)": [[59, "langtest.transform.fairness.MaxGenderF1Score.transform"]], "mingenderf1score (class in langtest.transform.fairness)": [[60, "langtest.transform.fairness.MinGenderF1Score"]], "__init__() (mingenderf1score method)": [[60, "langtest.transform.fairness.MinGenderF1Score.__init__"]], "alias_name (mingenderf1score attribute)": [[60, "langtest.transform.fairness.MinGenderF1Score.alias_name"]], "async_run() (mingenderf1score class method)": [[60, "langtest.transform.fairness.MinGenderF1Score.async_run"]], "run() (mingenderf1score method)": [[60, "langtest.transform.fairness.MinGenderF1Score.run"]], "transform() (mingenderf1score static method)": [[60, "langtest.transform.fairness.MinGenderF1Score.transform"]], "get_gendered_data() (in module langtest.transform.fairness)": [[61, "langtest.transform.fairness.get_gendered_data"]], "langtest.transform.representation": [[62, "module-langtest.transform.representation"]], "baserepresentation (class in langtest.transform.representation)": [[63, "langtest.transform.representation.BaseRepresentation"]], "__init__() (baserepresentation method)": [[63, "langtest.transform.representation.BaseRepresentation.__init__"]], "alias_name (baserepresentation attribute)": [[63, "langtest.transform.representation.BaseRepresentation.alias_name"]], "async_run() (baserepresentation class method)": [[63, "langtest.transform.representation.BaseRepresentation.async_run"]], "transform() (baserepresentation static method)": [[63, "langtest.transform.representation.BaseRepresentation.transform"]], "countryeconomicrepresentation (class in langtest.transform.representation)": [[64, "langtest.transform.representation.CountryEconomicRepresentation"]], "__init__() (countryeconomicrepresentation method)": [[64, "langtest.transform.representation.CountryEconomicRepresentation.__init__"]], "alias_name (countryeconomicrepresentation attribute)": [[64, "langtest.transform.representation.CountryEconomicRepresentation.alias_name"]], "async_run() (countryeconomicrepresentation class method)": [[64, "langtest.transform.representation.CountryEconomicRepresentation.async_run"]], "run() (countryeconomicrepresentation method)": [[64, "langtest.transform.representation.CountryEconomicRepresentation.run"]], "transform() (countryeconomicrepresentation method)": [[64, "langtest.transform.representation.CountryEconomicRepresentation.transform"]], "ethnicityrepresentation (class in langtest.transform.representation)": [[65, "langtest.transform.representation.EthnicityRepresentation"]], "__init__() (ethnicityrepresentation method)": [[65, "langtest.transform.representation.EthnicityRepresentation.__init__"]], "alias_name (ethnicityrepresentation attribute)": [[65, "langtest.transform.representation.EthnicityRepresentation.alias_name"]], "async_run() (ethnicityrepresentation class method)": [[65, "langtest.transform.representation.EthnicityRepresentation.async_run"]], "run() (ethnicityrepresentation method)": [[65, "langtest.transform.representation.EthnicityRepresentation.run"]], "transform() (ethnicityrepresentation method)": [[65, "langtest.transform.representation.EthnicityRepresentation.transform"]], "genderrepresentation (class in langtest.transform.representation)": [[66, "langtest.transform.representation.GenderRepresentation"]], "__init__() (genderrepresentation method)": [[66, "langtest.transform.representation.GenderRepresentation.__init__"]], "alias_name (genderrepresentation attribute)": [[66, "langtest.transform.representation.GenderRepresentation.alias_name"]], "async_run() (genderrepresentation class method)": [[66, "langtest.transform.representation.GenderRepresentation.async_run"]], "run() (genderrepresentation method)": [[66, "langtest.transform.representation.GenderRepresentation.run"]], "transform() (genderrepresentation method)": [[66, "langtest.transform.representation.GenderRepresentation.transform"]], "labelrepresentation (class in langtest.transform.representation)": [[67, "langtest.transform.representation.LabelRepresentation"]], "__init__() (labelrepresentation method)": [[67, "langtest.transform.representation.LabelRepresentation.__init__"]], "alias_name (labelrepresentation attribute)": [[67, "langtest.transform.representation.LabelRepresentation.alias_name"]], "async_run() (labelrepresentation class method)": [[67, "langtest.transform.representation.LabelRepresentation.async_run"]], "run() (labelrepresentation method)": [[67, "langtest.transform.representation.LabelRepresentation.run"]], "transform() (labelrepresentation method)": [[67, "langtest.transform.representation.LabelRepresentation.transform"]], "religionrepresentation (class in langtest.transform.representation)": [[68, "langtest.transform.representation.ReligionRepresentation"]], "__init__() (religionrepresentation method)": [[68, "langtest.transform.representation.ReligionRepresentation.__init__"]], "alias_name (religionrepresentation attribute)": [[68, "langtest.transform.representation.ReligionRepresentation.alias_name"]], "async_run() (religionrepresentation class method)": [[68, "langtest.transform.representation.ReligionRepresentation.async_run"]], "run() (religionrepresentation method)": [[68, "langtest.transform.representation.ReligionRepresentation.run"]], "transform() (religionrepresentation method)": [[68, "langtest.transform.representation.ReligionRepresentation.transform"]], "langtest.transform.robustness": [[69, "module-langtest.transform.robustness"]], "addcontext (class in langtest.transform.robustness)": [[70, "langtest.transform.robustness.AddContext"]], "__init__() (addcontext method)": [[70, "langtest.transform.robustness.AddContext.__init__"]], "async_run() (addcontext class method)": [[70, "langtest.transform.robustness.AddContext.async_run"]], "run() (addcontext static method)": [[70, "langtest.transform.robustness.AddContext.run"]], "transform() (addcontext static method)": [[70, "langtest.transform.robustness.AddContext.transform"]], "addcontraction (class in langtest.transform.robustness)": [[71, "langtest.transform.robustness.AddContraction"]], "__init__() (addcontraction method)": [[71, "langtest.transform.robustness.AddContraction.__init__"]], "async_run() (addcontraction class method)": [[71, "langtest.transform.robustness.AddContraction.async_run"]], "run() (addcontraction static method)": [[71, "langtest.transform.robustness.AddContraction.run"]], "transform() (addcontraction static method)": [[71, "langtest.transform.robustness.AddContraction.transform"]], "addpunctuation (class in langtest.transform.robustness)": [[72, "langtest.transform.robustness.AddPunctuation"]], "__init__() (addpunctuation method)": [[72, "langtest.transform.robustness.AddPunctuation.__init__"]], "async_run() (addpunctuation class method)": [[72, "langtest.transform.robustness.AddPunctuation.async_run"]], "run() (addpunctuation static method)": [[72, "langtest.transform.robustness.AddPunctuation.run"]], "transform() (addpunctuation static method)": [[72, "langtest.transform.robustness.AddPunctuation.transform"]], "addtypo (class in langtest.transform.robustness)": [[73, "langtest.transform.robustness.AddTypo"]], "__init__() (addtypo method)": [[73, "langtest.transform.robustness.AddTypo.__init__"]], "async_run() (addtypo class method)": [[73, "langtest.transform.robustness.AddTypo.async_run"]], "run() (addtypo static method)": [[73, "langtest.transform.robustness.AddTypo.run"]], "transform() (addtypo static method)": [[73, "langtest.transform.robustness.AddTypo.transform"]], "baserobustness (class in langtest.transform.robustness)": [[74, "langtest.transform.robustness.BaseRobustness"]], "__init__() (baserobustness method)": [[74, "langtest.transform.robustness.BaseRobustness.__init__"]], "alias_name (baserobustness attribute)": [[74, "langtest.transform.robustness.BaseRobustness.alias_name"]], "async_run() (baserobustness class method)": [[74, "langtest.transform.robustness.BaseRobustness.async_run"]], "run() (baserobustness static method)": [[74, "langtest.transform.robustness.BaseRobustness.run"]], "transform() (baserobustness static method)": [[74, "langtest.transform.robustness.BaseRobustness.transform"]], "convertaccent (class in langtest.transform.robustness)": [[75, "langtest.transform.robustness.ConvertAccent"]], "__init__() (convertaccent method)": [[75, "langtest.transform.robustness.ConvertAccent.__init__"]], "async_run() (convertaccent class method)": [[75, "langtest.transform.robustness.ConvertAccent.async_run"]], "run() (convertaccent static method)": [[75, "langtest.transform.robustness.ConvertAccent.run"]], "transform() (convertaccent static method)": [[75, "langtest.transform.robustness.ConvertAccent.transform"]], "lowercase (class in langtest.transform.robustness)": [[76, "langtest.transform.robustness.LowerCase"]], "__init__() (lowercase method)": [[76, "langtest.transform.robustness.LowerCase.__init__"]], "async_run() (lowercase class method)": [[76, "langtest.transform.robustness.LowerCase.async_run"]], "run() (lowercase static method)": [[76, "langtest.transform.robustness.LowerCase.run"]], "transform() (lowercase static method)": [[76, "langtest.transform.robustness.LowerCase.transform"]], "strippunctuation (class in langtest.transform.robustness)": [[77, "langtest.transform.robustness.StripPunctuation"]], "__init__() (strippunctuation method)": [[77, "langtest.transform.robustness.StripPunctuation.__init__"]], "async_run() (strippunctuation class method)": [[77, "langtest.transform.robustness.StripPunctuation.async_run"]], "run() (strippunctuation static method)": [[77, "langtest.transform.robustness.StripPunctuation.run"]], "transform() (strippunctuation static method)": [[77, "langtest.transform.robustness.StripPunctuation.transform"]], "swapentities (class in langtest.transform.robustness)": [[78, "langtest.transform.robustness.SwapEntities"]], "__init__() (swapentities method)": [[78, "langtest.transform.robustness.SwapEntities.__init__"]], "async_run() (swapentities class method)": [[78, "langtest.transform.robustness.SwapEntities.async_run"]], "run() (swapentities static method)": [[78, "langtest.transform.robustness.SwapEntities.run"]], "transform() (swapentities static method)": [[78, "langtest.transform.robustness.SwapEntities.transform"]], "titlecase (class in langtest.transform.robustness)": [[79, "langtest.transform.robustness.TitleCase"]], "__init__() (titlecase method)": [[79, "langtest.transform.robustness.TitleCase.__init__"]], "async_run() (titlecase class method)": [[79, "langtest.transform.robustness.TitleCase.async_run"]], "run() (titlecase static method)": [[79, "langtest.transform.robustness.TitleCase.run"]], "transform() (titlecase static method)": [[79, "langtest.transform.robustness.TitleCase.transform"]], "uppercase (class in langtest.transform.robustness)": [[80, "langtest.transform.robustness.UpperCase"]], "__init__() (uppercase method)": [[80, "langtest.transform.robustness.UpperCase.__init__"]], "async_run() (uppercase class method)": [[80, "langtest.transform.robustness.UpperCase.async_run"]], "run() (uppercase static method)": [[80, "langtest.transform.robustness.UpperCase.run"]], "transform() (uppercase static method)": [[80, "langtest.transform.robustness.UpperCase.transform"]], "langtest.transform.utils": [[81, "module-langtest.transform.utils"]], "check_name() (in module langtest.transform.utils)": [[82, "langtest.transform.utils.check_name"]], "create_terminology() (in module langtest.transform.utils)": [[83, "langtest.transform.utils.create_terminology"]], "get_country_economic_representation_dict() (in module langtest.transform.utils)": [[84, "langtest.transform.utils.get_country_economic_representation_dict"]], "get_entity_representation_proportions() (in module langtest.transform.utils)": [[85, "langtest.transform.utils.get_entity_representation_proportions"]], "get_ethnicity_representation_dict() (in module langtest.transform.utils)": [[86, "langtest.transform.utils.get_ethnicity_representation_dict"]], "get_label_representation_dict() (in module langtest.transform.utils)": [[87, "langtest.transform.utils.get_label_representation_dict"]], "get_religion_name_representation_dict() (in module langtest.transform.utils)": [[88, "langtest.transform.utils.get_religion_name_representation_dict"]], "get_substitution_names() (in module langtest.transform.utils)": [[89, "langtest.transform.utils.get_substitution_names"]], "langtest.utils": [[90, "module-langtest.utils"]], "langtest.utils.custom_types": [[91, "module-langtest.utils.custom_types"]], "langtest.utils.custom_types.helpers": [[92, "module-langtest.utils.custom_types.helpers"]], "span (class in langtest.utils.custom_types.helpers)": [[93, "langtest.utils.custom_types.helpers.Span"]], "__init__() (span method)": [[93, "langtest.utils.custom_types.helpers.Span.__init__"]], "construct() (span class method)": [[93, "langtest.utils.custom_types.helpers.Span.construct"]], "copy() (span method)": [[93, "langtest.utils.custom_types.helpers.Span.copy"]], "dict() (span method)": [[93, "langtest.utils.custom_types.helpers.Span.dict"]], "json() (span method)": [[93, "langtest.utils.custom_types.helpers.Span.json"]], "update_forward_refs() (span class method)": [[93, "langtest.utils.custom_types.helpers.Span.update_forward_refs"]], "transformation (class in langtest.utils.custom_types.helpers)": [[94, "langtest.utils.custom_types.helpers.Transformation"]], "__init__() (transformation method)": [[94, "langtest.utils.custom_types.helpers.Transformation.__init__"]], "construct() (transformation class method)": [[94, "langtest.utils.custom_types.helpers.Transformation.construct"]], "copy() (transformation method)": [[94, "langtest.utils.custom_types.helpers.Transformation.copy"]], "dict() (transformation method)": [[94, "langtest.utils.custom_types.helpers.Transformation.dict"]], "json() (transformation method)": [[94, "langtest.utils.custom_types.helpers.Transformation.json"]], "update_forward_refs() (transformation class method)": [[94, "langtest.utils.custom_types.helpers.Transformation.update_forward_refs"]], "langtest.utils.custom_types.output": [[95, "module-langtest.utils.custom_types.output"]], "maxscoreoutput (class in langtest.utils.custom_types.output)": [[96, "langtest.utils.custom_types.output.MaxScoreOutput"]], "__init__() (maxscoreoutput method)": [[96, "langtest.utils.custom_types.output.MaxScoreOutput.__init__"]], "construct() (maxscoreoutput class method)": [[96, "langtest.utils.custom_types.output.MaxScoreOutput.construct"]], "copy() (maxscoreoutput method)": [[96, "langtest.utils.custom_types.output.MaxScoreOutput.copy"]], "dict() (maxscoreoutput method)": [[96, "langtest.utils.custom_types.output.MaxScoreOutput.dict"]], "json() (maxscoreoutput method)": [[96, "langtest.utils.custom_types.output.MaxScoreOutput.json"]], "update_forward_refs() (maxscoreoutput class method)": [[96, "langtest.utils.custom_types.output.MaxScoreOutput.update_forward_refs"]], "minscoreoutput (class in langtest.utils.custom_types.output)": [[97, "langtest.utils.custom_types.output.MinScoreOutput"]], "__init__() (minscoreoutput method)": [[97, "langtest.utils.custom_types.output.MinScoreOutput.__init__"]], "construct() (minscoreoutput class method)": [[97, "langtest.utils.custom_types.output.MinScoreOutput.construct"]], "copy() (minscoreoutput method)": [[97, "langtest.utils.custom_types.output.MinScoreOutput.copy"]], "dict() (minscoreoutput method)": [[97, "langtest.utils.custom_types.output.MinScoreOutput.dict"]], "json() (minscoreoutput method)": [[97, "langtest.utils.custom_types.output.MinScoreOutput.json"]], "update_forward_refs() (minscoreoutput class method)": [[97, "langtest.utils.custom_types.output.MinScoreOutput.update_forward_refs"]], "neroutput (class in langtest.utils.custom_types.output)": [[98, "langtest.utils.custom_types.output.NEROutput"]], "__init__() (neroutput method)": [[98, "langtest.utils.custom_types.output.NEROutput.__init__"]], "construct() (neroutput class method)": [[98, "langtest.utils.custom_types.output.NEROutput.construct"]], "copy() (neroutput method)": [[98, "langtest.utils.custom_types.output.NEROutput.copy"]], "dict() (neroutput method)": [[98, "langtest.utils.custom_types.output.NEROutput.dict"]], "json() (neroutput method)": [[98, "langtest.utils.custom_types.output.NEROutput.json"]], "to_str_list() (neroutput method)": [[98, "langtest.utils.custom_types.output.NEROutput.to_str_list"]], "update_forward_refs() (neroutput class method)": [[98, "langtest.utils.custom_types.output.NEROutput.update_forward_refs"]], "sequenceclassificationoutput (class in langtest.utils.custom_types.output)": [[99, "langtest.utils.custom_types.output.SequenceClassificationOutput"]], "__init__() (sequenceclassificationoutput method)": [[99, "langtest.utils.custom_types.output.SequenceClassificationOutput.__init__"]], "construct() (sequenceclassificationoutput class method)": [[99, "langtest.utils.custom_types.output.SequenceClassificationOutput.construct"]], "copy() (sequenceclassificationoutput method)": [[99, "langtest.utils.custom_types.output.SequenceClassificationOutput.copy"]], "dict() (sequenceclassificationoutput method)": [[99, "langtest.utils.custom_types.output.SequenceClassificationOutput.dict"]], "json() (sequenceclassificationoutput method)": [[99, "langtest.utils.custom_types.output.SequenceClassificationOutput.json"]], "to_str_list() (sequenceclassificationoutput method)": [[99, "langtest.utils.custom_types.output.SequenceClassificationOutput.to_str_list"]], "update_forward_refs() (sequenceclassificationoutput class method)": [[99, "langtest.utils.custom_types.output.SequenceClassificationOutput.update_forward_refs"]], "langtest.utils.custom_types.predictions": [[100, "module-langtest.utils.custom_types.predictions"]], "nerprediction (class in langtest.utils.custom_types.predictions)": [[101, "langtest.utils.custom_types.predictions.NERPrediction"]], "__init__() (nerprediction method)": [[101, "langtest.utils.custom_types.predictions.NERPrediction.__init__"]], "construct() (nerprediction class method)": [[101, "langtest.utils.custom_types.predictions.NERPrediction.construct"]], "copy() (nerprediction method)": [[101, "langtest.utils.custom_types.predictions.NERPrediction.copy"]], "dict() (nerprediction method)": [[101, "langtest.utils.custom_types.predictions.NERPrediction.dict"]], "json() (nerprediction method)": [[101, "langtest.utils.custom_types.predictions.NERPrediction.json"]], "update_forward_refs() (nerprediction class method)": [[101, "langtest.utils.custom_types.predictions.NERPrediction.update_forward_refs"]], "sequencelabel (class in langtest.utils.custom_types.predictions)": [[102, "langtest.utils.custom_types.predictions.SequenceLabel"]], "__init__() (sequencelabel method)": [[102, "langtest.utils.custom_types.predictions.SequenceLabel.__init__"]], "construct() (sequencelabel class method)": [[102, "langtest.utils.custom_types.predictions.SequenceLabel.construct"]], "copy() (sequencelabel method)": [[102, "langtest.utils.custom_types.predictions.SequenceLabel.copy"]], "dict() (sequencelabel method)": [[102, "langtest.utils.custom_types.predictions.SequenceLabel.dict"]], "json() (sequencelabel method)": [[102, "langtest.utils.custom_types.predictions.SequenceLabel.json"]], "update_forward_refs() (sequencelabel class method)": [[102, "langtest.utils.custom_types.predictions.SequenceLabel.update_forward_refs"]], "langtest.utils.custom_types.sample": [[103, "module-langtest.utils.custom_types.sample"]], "baseqasample (class in langtest.utils.custom_types.sample)": [[104, "langtest.utils.custom_types.sample.BaseQASample"]], "__init__() (baseqasample method)": [[104, "langtest.utils.custom_types.sample.BaseQASample.__init__"]], "construct() (baseqasample class method)": [[104, "langtest.utils.custom_types.sample.BaseQASample.construct"]], "copy() (baseqasample method)": [[104, "langtest.utils.custom_types.sample.BaseQASample.copy"]], "dict() (baseqasample method)": [[104, "langtest.utils.custom_types.sample.BaseQASample.dict"]], "json() (baseqasample method)": [[104, "langtest.utils.custom_types.sample.BaseQASample.json"]], "update_forward_refs() (baseqasample class method)": [[104, "langtest.utils.custom_types.sample.BaseQASample.update_forward_refs"]], "basesample (class in langtest.utils.custom_types.sample)": [[105, "langtest.utils.custom_types.sample.BaseSample"]], "__init__() (basesample method)": [[105, "langtest.utils.custom_types.sample.BaseSample.__init__"]], "construct() (basesample class method)": [[105, "langtest.utils.custom_types.sample.BaseSample.construct"]], "copy() (basesample method)": [[105, "langtest.utils.custom_types.sample.BaseSample.copy"]], "dict() (basesample method)": [[105, "langtest.utils.custom_types.sample.BaseSample.dict"]], "irrelevant_transformations (basesample property)": [[105, "langtest.utils.custom_types.sample.BaseSample.irrelevant_transformations"]], "json() (basesample method)": [[105, "langtest.utils.custom_types.sample.BaseSample.json"]], "relevant_transformations (basesample property)": [[105, "langtest.utils.custom_types.sample.BaseSample.relevant_transformations"]], "sort_transformations() (basesample class method)": [[105, "langtest.utils.custom_types.sample.BaseSample.sort_transformations"]], "to_dict() (basesample method)": [[105, "langtest.utils.custom_types.sample.BaseSample.to_dict"]], "update_forward_refs() (basesample class method)": [[105, "langtest.utils.custom_types.sample.BaseSample.update_forward_refs"]], "maxscoresample (class in langtest.utils.custom_types.sample)": [[106, "langtest.utils.custom_types.sample.MaxScoreSample"]], "__init__() (maxscoresample method)": [[106, "langtest.utils.custom_types.sample.MaxScoreSample.__init__"]], "construct() (maxscoresample class method)": [[106, "langtest.utils.custom_types.sample.MaxScoreSample.construct"]], "copy() (maxscoresample method)": [[106, "langtest.utils.custom_types.sample.MaxScoreSample.copy"]], "dict() (maxscoresample method)": [[106, "langtest.utils.custom_types.sample.MaxScoreSample.dict"]], "irrelevant_transformations (maxscoresample property)": [[106, "langtest.utils.custom_types.sample.MaxScoreSample.irrelevant_transformations"]], "json() (maxscoresample method)": [[106, "langtest.utils.custom_types.sample.MaxScoreSample.json"]], "relevant_transformations (maxscoresample property)": [[106, "langtest.utils.custom_types.sample.MaxScoreSample.relevant_transformations"]], "sort_transformations() (maxscoresample class method)": [[106, "langtest.utils.custom_types.sample.MaxScoreSample.sort_transformations"]], "to_dict() (maxscoresample method)": [[106, "langtest.utils.custom_types.sample.MaxScoreSample.to_dict"]], "update_forward_refs() (maxscoresample class method)": [[106, "langtest.utils.custom_types.sample.MaxScoreSample.update_forward_refs"]], "minscoresample (class in langtest.utils.custom_types.sample)": [[107, "langtest.utils.custom_types.sample.MinScoreSample"]], "__init__() (minscoresample method)": [[107, "langtest.utils.custom_types.sample.MinScoreSample.__init__"]], "construct() (minscoresample class method)": [[107, "langtest.utils.custom_types.sample.MinScoreSample.construct"]], "copy() (minscoresample method)": [[107, "langtest.utils.custom_types.sample.MinScoreSample.copy"]], "dict() (minscoresample method)": [[107, "langtest.utils.custom_types.sample.MinScoreSample.dict"]], "irrelevant_transformations (minscoresample property)": [[107, "langtest.utils.custom_types.sample.MinScoreSample.irrelevant_transformations"]], "json() (minscoresample method)": [[107, "langtest.utils.custom_types.sample.MinScoreSample.json"]], "relevant_transformations (minscoresample property)": [[107, "langtest.utils.custom_types.sample.MinScoreSample.relevant_transformations"]], "sort_transformations() (minscoresample class method)": [[107, "langtest.utils.custom_types.sample.MinScoreSample.sort_transformations"]], "to_dict() (minscoresample method)": [[107, "langtest.utils.custom_types.sample.MinScoreSample.to_dict"]], "update_forward_refs() (minscoresample class method)": [[107, "langtest.utils.custom_types.sample.MinScoreSample.update_forward_refs"]], "nersample (class in langtest.utils.custom_types.sample)": [[108, "langtest.utils.custom_types.sample.NERSample"]], "__init__() (nersample method)": [[108, "langtest.utils.custom_types.sample.NERSample.__init__"]], "construct() (nersample class method)": [[108, "langtest.utils.custom_types.sample.NERSample.construct"]], "copy() (nersample method)": [[108, "langtest.utils.custom_types.sample.NERSample.copy"]], "dict() (nersample method)": [[108, "langtest.utils.custom_types.sample.NERSample.dict"]], "get_aligned_span_pairs() (nersample method)": [[108, "langtest.utils.custom_types.sample.NERSample.get_aligned_span_pairs"]], "ignored_predictions (nersample property)": [[108, "langtest.utils.custom_types.sample.NERSample.ignored_predictions"]], "irrelevant_transformations (nersample property)": [[108, "langtest.utils.custom_types.sample.NERSample.irrelevant_transformations"]], "json() (nersample method)": [[108, "langtest.utils.custom_types.sample.NERSample.json"]], "realigned_spans (nersample property)": [[108, "langtest.utils.custom_types.sample.NERSample.realigned_spans"]], "relevant_transformations (nersample property)": [[108, "langtest.utils.custom_types.sample.NERSample.relevant_transformations"]], "sort_transformations() (nersample class method)": [[108, "langtest.utils.custom_types.sample.NERSample.sort_transformations"]], "to_dict() (nersample method)": [[108, "langtest.utils.custom_types.sample.NERSample.to_dict"]], "update_forward_refs() (nersample class method)": [[108, "langtest.utils.custom_types.sample.NERSample.update_forward_refs"]], "qasample (class in langtest.utils.custom_types.sample)": [[109, "langtest.utils.custom_types.sample.QASample"]], "__init__() (qasample method)": [[109, "langtest.utils.custom_types.sample.QASample.__init__"]], "construct() (qasample class method)": [[109, "langtest.utils.custom_types.sample.QASample.construct"]], "copy() (qasample method)": [[109, "langtest.utils.custom_types.sample.QASample.copy"]], "dict() (qasample method)": [[109, "langtest.utils.custom_types.sample.QASample.dict"]], "json() (qasample method)": [[109, "langtest.utils.custom_types.sample.QASample.json"]], "to_dict() (qasample method)": [[109, "langtest.utils.custom_types.sample.QASample.to_dict"]], "update_forward_refs() (qasample class method)": [[109, "langtest.utils.custom_types.sample.QASample.update_forward_refs"]], "sequenceclassificationsample (class in langtest.utils.custom_types.sample)": [[110, "langtest.utils.custom_types.sample.SequenceClassificationSample"]], "__init__() (sequenceclassificationsample method)": [[110, "langtest.utils.custom_types.sample.SequenceClassificationSample.__init__"]], "construct() (sequenceclassificationsample class method)": [[110, "langtest.utils.custom_types.sample.SequenceClassificationSample.construct"]], "copy() (sequenceclassificationsample method)": [[110, "langtest.utils.custom_types.sample.SequenceClassificationSample.copy"]], "dict() (sequenceclassificationsample method)": [[110, "langtest.utils.custom_types.sample.SequenceClassificationSample.dict"]], "irrelevant_transformations (sequenceclassificationsample property)": [[110, "langtest.utils.custom_types.sample.SequenceClassificationSample.irrelevant_transformations"]], "json() (sequenceclassificationsample method)": [[110, "langtest.utils.custom_types.sample.SequenceClassificationSample.json"]], "relevant_transformations (sequenceclassificationsample property)": [[110, "langtest.utils.custom_types.sample.SequenceClassificationSample.relevant_transformations"]], "sort_transformations() (sequenceclassificationsample class method)": [[110, "langtest.utils.custom_types.sample.SequenceClassificationSample.sort_transformations"]], "to_dict() (sequenceclassificationsample method)": [[110, "langtest.utils.custom_types.sample.SequenceClassificationSample.to_dict"]], "update_forward_refs() (sequenceclassificationsample class method)": [[110, "langtest.utils.custom_types.sample.SequenceClassificationSample.update_forward_refs"]], "langtest.utils.gender_classifier": [[111, "module-langtest.utils.gender_classifier"]], "genderclassifier (class in langtest.utils.gender_classifier)": [[112, "langtest.utils.gender_classifier.GenderClassifier"]], "__init__() (genderclassifier method)": [[112, "langtest.utils.gender_classifier.GenderClassifier.__init__"]], "predict() (genderclassifier method)": [[112, "langtest.utils.gender_classifier.GenderClassifier.predict"]], "langtest.utils.lib_manager": [[113, "module-langtest.utils.lib_manager"]], "try_import_lib() (in module langtest.utils.lib_manager)": [[114, "langtest.utils.lib_manager.try_import_lib"]]}})